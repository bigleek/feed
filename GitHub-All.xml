<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>GitHub-All</title>
    <link>https://mshibanami.github.io/GitHubTrendingRSS/daily/all.xml</link>
    <description>Summarized RSS feed for GitHub-All</description>
    <atom:link href="https://mshibanami.github.io/GitHubTrendingRSS/daily/all.xml" rel="self" type="application/rss+xml"/>
    <item>
      <title>sansan0/TrendRadar</title>
      <link>https://github.com/sansan0/TrendRadar</link>
      <description>&lt;p&gt;概要: TrendRadar 是一款专为忙碌高管设计的智能热点资讯监控工具，具备多平台热点聚合与基于MCP协议的AI分析功能，支持35个主流平台数据采集，提供智能筛选、自动推送及13种深度分析功能，适配企业微信、飞书、钉钉、Telegram、邮件等多种通知渠道，实现快速部署和高频精准推送，结合关键词筛选和推送模式，满足企业舆情监控、投资决策、内容创作等多场景需求。项目采用轻量设计，无需编程即可操作，支持Docker部署及自动化数据管理，有效减少信息过载问题。&lt;/p&gt;

&lt;h3&gt;核心要点:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;多平台实时聚集： &lt;/strong&gt;覆盖抖音、知乎、今日头条等35个主流平台，自动抓取全球热点，避免信息过载。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;智能AI分析支持： &lt;/strong&gt; 搭载MCP AI对话分析系统，支持趋势追踪、情感分析、跨平台对比等13种分析工具，可深度挖掘信息。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;多渠道推送与个性化配置： &lt;/strong&gt; 推送支持企业微信、Slack、Telegram、邮件等，配备灵活配置工具，在config/config.yaml中设置推送模式与推送频率。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;关键词与词组管理： &lt;/strong&gt; 支持普通词、必须词、过滤词和数量限制，实现专注式监控，提升热点信息的精准度和效率。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;轻量部署和跨平台适配： &lt;/strong&gt; 提供30秒网页部署、1分钟手机端通知，支持GitHub Pages、Docker本地化、多设备多平台适配，降低使用门槛。&lt;/li&gt;
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/sansan0/TrendRadar</guid>
    </item>
    <item>
      <title>traefik/traefik</title>
      <link>https://github.com/traefik/traefik</link>
      <description>&lt;p&gt;概要: Traefik 是一款现代的 HTTP 反向代理和负载均衡器，专为简化云原生微服务部署而设计，能够自动与 Docker、Kubernetes、ECS 等基础设施组件集成，动态配置路由，无需手动维护，同时提供 HTTPS 支持、Web 界面、多种负载均衡算法及丰富的监控和日志功能。&lt;/p&gt;  
&lt;h3&gt;核心要点:&lt;/h3&gt;  
&lt;ul&gt;  
  &lt;li&gt;&lt;strong&gt;自动动态配置路由&lt;/strong&gt;：Traefik 通过监听服务注册中心或编排器 API 自动生成路由配置，无需手动干预。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;支持多种云原生基础设施&lt;/strong&gt;：兼容 Docker、Kubernetes、ECS、Consul、Etcd 等主流平台，实现无缝集成。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;提供 HTTPS 与安全功能&lt;/strong&gt;：集成 Let's Encrypt 以自动获取和更新 SSL 证书，支持电路断路器、重试等安全机制。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;轻量易用且功能丰富&lt;/strong&gt;：以单个二进制文件或官方 Docker 镜像提供，性能高效，并支持 REST API、Web UI 和多种监控工具。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;开放协作的社区与支持&lt;/strong&gt;：鼓励开放贡献，提供社区论坛和商业支持渠道，并遵循语义化版本控制规范。&lt;/li&gt;  
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/traefik/traefik</guid>
    </item>
    <item>
      <title>yangshun/tech-interview-handbook</title>
      <link>https://github.com/yangshun/tech-interview-handbook</link>
      <description>&lt;p&gt;概要: 《Tech Interview Handbook》为忙碌的软件工程师提供精心整理的免费技术面试准备资源，覆盖算法、简历指导、行为面试问题及前端等内容，帮助用户高效应对技术面试，专注于实践和策略而非盲目刷题。&lt;/p&gt;

&lt;h3&gt;核心要点:&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;提供结构化且高效的面试准备内容&lt;/strong&gt;，涵盖算法、简历、行为面试等多方面，并强调通过问题模式学习而不是单纯记忆答案。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;特别针对时间有限的工程师&lt;/strong&gt;，避免冗长的理论讲解，提供简洁、实用的指导，帮助用户快速掌握关键知识点。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;整合非技术面试内容&lt;/strong&gt;，包括简历优化、行为面试问题及面试流程中的其他关键环节，满足全面准备的需求。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;推荐相关资源&lt;/strong&gt;，如AlgoMonster和Grokking系列课程，为用户提供更多高效学习路径。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;鼓励社区参与和贡献&lt;/strong&gt;，以持续完善内容，并为项目提供支持，如赞助和捐赠。&lt;/li&gt;
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/yangshun/tech-interview-handbook</guid>
    </item>
    <item>
      <title>volcengine/verl</title>
      <link>https://github.com/volcengine/verl</link>
      <description>&lt;p&gt;概要: verl 是由字节跳动种子团队主导、社区维护的高效且灵活的大语言模型（LLM）强化学习训练库，支持多种主流框架与模型，具备出色的吞吐量和资源利用效率，已在多个前沿项目中实现卓越性能，如 Qwen2.5-32B、DeepSeek-671B 和 Qwen3-235B 等，且持续通过社区贡献和技术创新推动 RLHF（基于人类反馈的强化学习）框架的发展。&lt;/p&gt;

&lt;h3&gt;核心要点:&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;高效灵活的 RL 训练框架&lt;/strong&gt;：verl 是一个生产就绪的 RL 训练库，支持多种算法如 PPO、GRPO、DAPO 等，并提供模块化 API 与灵活的设备映射，便于扩展和集成。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;卓越性能与吞吐量&lt;/strong&gt;：具备行业领先的训练和推理吞吐量，支持 FSDP2、vLLM 和 SGLang 等高效后端，实现大规模模型（如 671B）的快速训练。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;多领域通用性与扩展性&lt;/strong&gt;：适用于数学、编程、多模态模型（如 VLM）和工具调用场景，支持复杂多步骤推理任务和多种强化学习方法的自定义扩展。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;广泛社区支持与活跃生态&lt;/strong&gt;：由多个顶尖机构与公司联合开发与维护，包括字节跳动、阿里云、NVIDIA 等，社区贡献众多先进算法与应用场景。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;多平台兼容与部署支持&lt;/strong&gt;：兼容 HuggingFace 模型与 ModelScope，且支持 AWS SageMaker、ROCm 等部署环境，提升训练与推理的灵活性和可扩展性。&lt;/li&gt;
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/volcengine/verl</guid>
    </item>
    <item>
      <title>yeongpin/cursor-free-vip</title>
      <link>https://github.com/yeongpin/cursor-free-vip</link>
      <description>&lt;p&gt;概要: 该工具支持 Cursor AI 的 0.49.x 版本，提供自动重置机器 ID 和绕过更高 token 限制的功能，以便免费升级使用 Pro 功能。它适用于 Windows、macOS 和 Linux 系统，具备多语言支持和可配置的运行参数，用于教育和研究目的，强调合法性和用户责任。&lt;/p&gt;  
&lt;h3&gt;核心要点:&lt;/h3&gt;  
&lt;ul&gt;  
  &lt;li&gt;&lt;strong&gt;支持 0.49.x 版本并绕过 token 限制&lt;/strong&gt;：通过重置机器 ID 和调整配置，实现免费升级使用 Pro 功能，适用于教育和研究场景。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;跨平台兼容性&lt;/strong&gt;：支持 Windows、macOS 和 Linux 操作系统，覆盖不同架构类型，确保广泛适用性。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;用户需以管理员权限运行脚本并关闭 Cursor&lt;/strong&gt;：为避免权限问题和确保脚本正常执行，需提前关闭 Cursor 并使用管理员权限运行。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;工具仅限学习与研究，不生成虚假邮箱或 OAuth 访问&lt;/strong&gt;：声明工具用途合法，不涉及违规操作，强调用户需遵守相关软件条款。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;配置文件可自定义路径及各种等待时间&lt;/strong&gt;：提供详细的配置选项，包括浏览器路径、验证等待时间、重试设置等，增强灵活性与控制能力。&lt;/li&gt;  
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/yeongpin/cursor-free-vip</guid>
    </item>
    <item>
      <title>TapXWorld/ChinaTextbook</title>
      <link>https://github.com/TapXWorld/ChinaTextbook</link>
      <description>&lt;p&gt;概要: 本项目旨在提供从小学到大学的完整PDF教材资源，通过开源和集中管理应对教育资源获取受限的问题，特别关注国内普通民众与海外华人子女的教育需求，并提供文件合并工具以解决因GitHub文件大小限制导致的拆分问题，鼓励用户捐赠支持开放教育的持续发展。&lt;/p&gt;

&lt;h3&gt;核心要点:&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;项目目标&lt;/strong&gt;: 提供覆盖小初高及大学的完整PDF教材，推动义务教育普及，减少地区教育差距。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;针对性用户群体&lt;/strong&gt;: 特别关注海外华人子女，确保其能继续接触国内教育内容。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;文件拆分与合并机制&lt;/strong&gt;: 因GitHub限制，大文件被拆分为多个35MB文件，提供专用合并程序以方便用户整合。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;下载与访问策略&lt;/strong&gt;: 内地用户可使用开源项目重新下载，海外用户建议使用本存储库以提升下载效率。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;开源与公益理念&lt;/strong&gt;: 鼓励开源精神，倡导用户支持项目并通过捐赠助力资源库的维护与扩展。&lt;/li&gt;
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/TapXWorld/ChinaTextbook</guid>
    </item>
    <item>
      <title>HKUDS/LightRAG</title>
      <link>https://github.com/HKUDS/LightRAG</link>
      <description>&lt;p&gt;概要: LightRAG 是一个简单且高效的检索增强生成系统，为多模态文档处理、知识图谱管理、多模型支持以及性能优化做出了多项创新，同时还支持与 Langfuse 和 RAGAS 的集成，以实现观察和评估功能，极大地提升了系统的实用性与灵活性。&lt;/p&gt;

&lt;h3&gt;核心要点:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;多模态集成&lt;/strong&gt;: LightRAG 集成 RAG-Anything，支持文本、图像、表格和公式等多模态数据处理。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;知识图谱增强&lt;/strong&gt;: 提升了小型 LLM 的知识图谱抽取准确率，并提供删除与恢复机制以确保查询性能。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;多存储适配&lt;/strong&gt;: 支持多种存储后端，如 Neo4J、PostgreSQL、MongoDB 和 Redis，以提升数据管理灵活性。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;性能优化&lt;/strong&gt;: 可通过增大上下文窗口、使用流式处理以及优化并行处理参数，提升大规模数据处理效率。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;可观测性与评估&lt;/strong&gt;: 集成 Langfuse 进行LLM交互追踪，并集成 RAGAS 提供无需参照物的评估机制，使系统更便于监控与优化。&lt;/li&gt;
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/HKUDS/LightRAG</guid>
    </item>
    <item>
      <title>MustardChef/WSABuilds</title>
      <link>https://github.com/MustardChef/WSABuilds</link>
      <description>&lt;p&gt;概要: 该文本详细介绍了如何在Windows 10和Windows 11上使用WSABuilds提供的预编译二进制文件安装Windows Subsystem For Android (WSA)，支持Google Play Store、Magisk和KernelSU等组件。同时指出近期Windows更新导致WSA安装问题，并提供解决方法，如使用旧版本、避免GApps或使用特定的LTS版本。此外，涵盖了系统需求、安装与卸载方法、数据备份恢复、常见问题及解决途径、应用程序兼容性列表等。&lt;/p&gt; 

&lt;h3&gt;核心要点:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Windows更新影响WSA稳定性&lt;/strong&gt;：自今年7月起，Windows更新引发了WSA安装问题，推荐使用旧版本或无GApps的Builds。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;WSABuilds支持Magisk和GApps&lt;/strong&gt;：WSABuilds提供了内含Magisk和Google应用的预编译版WSA，支持长期维护（LTS）和常规更新，且持续更新以确保兼容性。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;系统兼容性与配置要求&lt;/strong&gt;：需满足Windows 10或11的特定系统要求，包括Build版本、虚拟化支持、存储和分区类型、RAM及处理器等。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;应用程序兼容性存在差异&lt;/strong&gt;：不同应用在WSA上的表现各异，部分应用需要Google服务，部分存在UI问题或性能限制。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;备份和恢复方式&lt;/strong&gt;：备份和恢复用户数据需要备份Userdata.vhdx文件，并在重装WSA后还原。&lt;/li&gt;
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/MustardChef/WSABuilds</guid>
    </item>
    <item>
      <title>google/adk-go</title>
      <link>https://github.com/google/adk-go</link>
      <description>&lt;p&gt;概要: Google推出了一款基于Go语言的开源、代码优先工具包Agent Development Kit (ADK)，旨在为开发者提供灵活、可控的框架，用于构建、评估和部署复杂的AI代理，支持云原生环境，并兼容多种模型和部署方式。&lt;/p&gt;  
&lt;h3&gt;核心要点:&lt;/h3&gt;  
&lt;ul&gt;  
  &lt;li&gt;&lt;strong&gt;模型与部署无关&lt;/strong&gt;：ADK适用于多种AI模型，且不局限于特定部署方式，提供广泛的兼容性。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;强调代码优先开发&lt;/strong&gt;：允许开发者直接在Go中定义代理逻辑、工具和流程，提升灵活性和可测试性。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;支持多代理系统构建&lt;/strong&gt;：通过模块化设计，开发者可以组合多个专用代理以构建可扩展的应用。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;云原生优化&lt;/strong&gt;：充分利用Go语言在并发和性能方面的优势，适用于云原生代理应用的开发与部署。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;开源与许可协议&lt;/strong&gt;：项目采用Apache 2.0许可协议，除内部工具httprr外，其余部分均遵循此协议。&lt;/li&gt;  
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/google/adk-go</guid>
    </item>
    <item>
      <title>Zie619/n8n-workflows</title>
      <link>https://github.com/Zie619/n8n-workflows</link>
      <description>&lt;p&gt;概要: n8n Workflow Collection 是一个集成了4,343个生产级工作流的自动化平台，提供安全审计、多平台Docker支持、快速搜索与直观分类，通过现代化界面和高效性能提升用户体验，同时支持本地安装和在线使用，并鼓励社区贡献与反馈。&lt;/p&gt;  
&lt;h3&gt;核心要点:&lt;/h3&gt;  
&lt;ul&gt;  
  &lt;li&gt;&lt;strong&gt;大规模生产可用工作流&lt;/strong&gt;: 收录4,343个可直接导入使用的自动化工作流，覆盖365个独特服务和15个组织良好的分类。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;高性能与安全优化&lt;/strong&gt;: 采用SQLite FTS5实现100倍更快的搜索速度，支持&lt;50MB内存运行，并进行全面安全审计与CVE修复。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;便捷的在线访问与部署&lt;/strong&gt;: 提供GitHub Pages在线界面，支持无需安装的快速访问，且兼容Docker部署与本地安装。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;灵活的过滤与搜索功能&lt;/strong&gt;: 支持按类别、复杂度、触发类型和服务等多维度进行搜索和筛选，提升查找效率。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;开放贡献与社区支持&lt;/strong&gt;: 鼓励开发者通过报告问题、提交修复、建议功能等方式参与项目，并提供清晰的开发流程与文档支持。&lt;/li&gt;  
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/Zie619/n8n-workflows</guid>
    </item>
    <item>
      <title>bobeff/open-source-games</title>
      <link>https://github.com/bobeff/open-source-games</link>
      <description>&lt;p&gt;概要: 本文列举了多种开源视频游戏和商业游戏的开源重制版本，涵盖了动作、冒险、策略、角色扮演等类型，展示了开源社区在游戏开发与重构方面的多样性和创新能力，包括完整源代码还原、引擎重写、现代平台移植等项目。&lt;/p&gt;

&lt;h3&gt;核心要点:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;覆盖广泛的游戏类型&lt;/strong&gt;：包括动作、冒险、策略、角色扮演、沙盒、射击等，体现了开源游戏开发的全面性。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;包含经典游戏的开源重制&lt;/strong&gt;：如《Doom》《Wolfenstein 3D》《Command &amp; Conquer Generals》等，通过逆向工程与现代引擎实现重构。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;提供免费且可修改的源代码&lt;/strong&gt;：多数游戏项目支持源代码开源，便于开发者自由使用、修改和扩展。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;强调社区协作与创新&lt;/strong&gt;：如Minosoft、reone等项目，体现了开源社区在游戏开发中的重要作用。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;跨平台与多语言支持&lt;/strong&gt;：部分游戏使用JavaScript、Godot、Unity等技术，具备良好的跨平台适配能力。&lt;/li&gt;
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/bobeff/open-source-games</guid>
    </item>
    <item>
      <title>GibsonAI/Memori</title>
      <link>https://github.com/GibsonAI/Memori</link>
      <description>&lt;p&gt;概要: Memori 是一款开放源代码的 SQL 原生记忆引擎，允许任何大语言模型（LLM）、AI 代理或多代理系统通过一行代码实现持久化、可查询的记忆存储，使用标准 SQL 数据库进行管理，支持多框架集成，并提供智能记忆处理与成本优化，同时为未来的企业级 AI 记忆架构 Memori v3 开启了封闭内测。&lt;/p&gt;

&lt;h3&gt;核心要点:&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;一行代码实现 LLM 持久记忆&lt;/strong&gt;：通过 simple API 调用 memori.enable() 即可为任何 LLM 提供可查询的记忆存储。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;支持多种 SQL 数据库&lt;/strong&gt;：兼容 SQLite、PostgreSQL、MySQL、Neon 和 Supabase，确保灵活与可控。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;显著降低存储成本&lt;/strong&gt;：无需昂贵的向量数据库，节省 80-90% 的成本。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;全面框架兼容性&lt;/strong&gt;：支持 OpenAI、Anthropic、LiteLLM、LangChain 等主流 LLM 框架，通过 LiteLLM 回调系统实现无缝集成。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;智能记忆管理&lt;/strong&gt;：自动提取实体、建立关系并优先处理关键信息，同时支持上下文迁移与长期记忆优化。&lt;/li&gt;
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/GibsonAI/Memori</guid>
    </item>
    <item>
      <title>iptv-org/iptv</title>
      <link>https://github.com/iptv-org/iptv</link>
      <description>&lt;p&gt;概要: 该文本介绍了全球公开可用的IPTV频道集合，提供多种资源如播放列表、电子节目指南、数据库、API文档和相关工具，并强调所有内容均为用户提交的流媒体链接，而非存储视频文件，同时说明了如何使用及贡献方式。&lt;/p&gt;  
&lt;h3&gt;核心要点:&lt;/h3&gt;  
&lt;ul&gt;  
  &lt;li&gt;&lt;strong&gt;提供全球公开IPTV频道链接集合&lt;/strong&gt;，适用于直播流媒体播放。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;主要播放列表链接为&lt;/strong&gt; https://iptv-org.github.io/iptv/index.m3u。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;通过专用工具可获取电子节目指南（EPG）&lt;/strong&gt;，支持部分频道。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;所有频道数据来源于开放的数据库&lt;/strong&gt;，用户可反馈错误。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;不存储视频文件&lt;/strong&gt;，仅提供用户提交的公开流媒体URL链接。&lt;/li&gt;  
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/iptv-org/iptv</guid>
    </item>
    <item>
      <title>playcanvas/engine</title>
      <link>https://github.com/playcanvas/engine</link>
      <description>&lt;p&gt;概要: PlayCanvas 是一款基于 WebGL、WebGPU、WebXR 和 glTF 构建的开源游戏引擎，专为运行跨平台的 2D/3D 交互内容而设计，已被全球多家领先企业采用，并提供丰富的功能包括高级图形渲染、物理引擎集成、异步资产加载及多种输入方式支持。&lt;/p&gt;

&lt;h3&gt;核心要点:&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;跨平台支持&lt;/strong&gt;: PlayCanvas 在任何移动或桌面浏览器上均可运行基于 HTML5 和 WebGL 的游戏和交互内容。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;广泛行业应用&lt;/strong&gt;: 被包括迪士尼、宝马、Facebook、三星等在内的领军企业用于游戏、广告和可视化项目。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;高性能图形渲染&lt;/strong&gt;: 基于 WebGL2 和 WebGPU 实现先进的 2D/3D 图形处理能力。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;多样化特性&lt;/strong&gt;: 提供动画、物理、输入、音频、资源加载和脚本开发等全套功能模块。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;开发灵活性&lt;/strong&gt;: 支持 TypeScript 或 JavaScript 编写游戏逻辑，且提供本地开发环境搭建指南和构建命令。&lt;/li&gt;
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/playcanvas/engine</guid>
    </item>
    <item>
      <title>wolfpld/tracy</title>
      <link>https://github.com/wolfpld/tracy</link>
      <description>&lt;p&gt;概要: Tracy Profiler 是一款专为游戏及其他应用设计的实时、纳秒级精度、远程遥测的混合帧与采样型性能分析工具，支持多种语言和图形API，能够全面分析CPU和GPU性能、内存分配、锁机制、上下文切换，并自动关联截图与帧信息，为优化提供精准数据。&lt;/p&gt;

&lt;h3&gt;核心要点:&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;实时纳秒级性能分析&lt;/strong&gt;：Tracy Profiler 提供纳秒级的时间分辨率，支持对CPU和GPU进行实时性能监控。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;多语言与API支持&lt;/strong&gt;：原生支持C、C++、Lua、Python和Fortran，同时提供第三方绑定支持Rust、Zig、C#等多种语言及图形API（如OpenGL、Vulkan、Direct3D等）。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;全面性能追踪功能&lt;/strong&gt;：可追踪内存分配、锁机制、上下文切换等关键性能指标，便于深入排查性能瓶颈。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;自动截图与帧关联&lt;/strong&gt;：系统能自动将截图与捕捉到的帧信息进行匹配，提升调试与分析效率。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;文档与发布资源齐全&lt;/strong&gt;：提供详细文档和预编译的Windows x64二进制文件，便于快速上手与部署。&lt;/li&gt;
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/wolfpld/tracy</guid>
    </item>
    <item>
      <title>nvm-sh/nvm</title>
      <link>https://github.com/nvm-sh/nvm</link>
      <description>&lt;p&gt;概要: Node Version Manager (nvm) 是一个 POSIX 兼容的 Bash 脚本，用于轻松管理多个 node.js 版本，支持跨平台安装、自动切换版本、配置 .nvmrc 文件以实现更深度的 shell 集成，并提供 LTS 支持以及自定义颜色和镜像选项，适用于开发、CI/CD 流水线，以及 Docker 环境。&lt;/p&gt;  

&lt;h3&gt;核心要点:&lt;/h3&gt;  
&lt;ul&gt;  
&lt;li&gt;&lt;strong&gt;跨平台支持&lt;/strong&gt;：nvm 支持 Bash、Zsh、Fish 等多种 shell，并兼容 Linux、macOS 和 WSL，但 Fish 支持有限，需借助第三方工具。&lt;/li&gt;  
&lt;li&gt;&lt;strong&gt;LTS 版本管理&lt;/strong&gt;：支持通过 &lt;em&gt;lts/*&lt;/em&gt; 和 &lt;em&gt;lts/&lt;/em&gt; 版本名，方便选择长期支持版本，并可附带迁移 npm 包和更新 npm 的功能。&lt;/li&gt;  
&lt;li&gt;&lt;strong&gt;安装与更新方式灵活&lt;/strong&gt;：可通过 curl 或 wget 安装，支持在 Docker 中使用，能够通过设置 BASH_ENV 变量实现在非交互式环境下正常运行。&lt;/li&gt;  
&lt;li&gt;&lt;strong&gt;版本切换与自定义配置&lt;/strong&gt;：可使用 .nvmrc 文件自动切换 Node.js 版本，支持创建别名、设置默认版本、颜色自定义和路径恢复。&lt;/li&gt;  
&lt;li&gt;&lt;strong&gt;平台兼容性与异常处理&lt;/strong&gt;：在 Alpine Linux 和 macOS Apple Silicon 上需特别注意编译方式和依赖配置，某些系统可能需要使用源码安装或通过 Rosetta 运行 x86_64 架构的二进制文件。&lt;/li&gt;  
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/nvm-sh/nvm</guid>
    </item>
    <item>
      <title>milvus-io/milvus</title>
      <link>https://github.com/milvus-io/milvus</link>
      <description>&lt;p&gt;概要: Milvus 是一款高性能、云原生的向量数据库，专为大规模向量近似最近邻（ANN）搜索设计，支持多种索引类型和硬件加速，适用于文本、图像等多模态数据的高效处理，提供灵活的多租户架构、实时数据更新和精细的访问控制，旨在为AI应用如RAG、语义搜索和推荐系统提供可靠、安全且可扩展的解决方案。&lt;/p&gt;

&lt;h3&gt;核心要点:&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;高性能与云原生架构&lt;/strong&gt;：基于Go和C++开发，支持CPU/GPU硬件加速，具备分布式、K8s原生架构，实现横向扩展和高吞吐量。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;多索引类型与混合搜索能力&lt;/strong&gt;：支持HNSW、IVF、FLAT、SCANN、DiskANN等多种向量索引，同时兼容密集向量和稀疏向量，实现语义搜索与全文搜索的融合。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;灵活多租户与热冷存储机制&lt;/strong&gt;：可在数据库、集合、分区等层级实现租户隔离，支持热冷存储策略以优化成本与性能。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;全面集成与生态系统支持&lt;/strong&gt;：无缝整合LangChain、LlamaIndex、OpenAI、HuggingFace等AI工具，提供数据迁移、同步、监控及连接器等配套工具。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;开放源码与社区支持&lt;/strong&gt;：在LF AI &amp; Data Foundation下开源，采用Apache 2.0许可证，支持贡献与社区协作，提供文档、FAQ及多种部署方式。&lt;/li&gt;
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/milvus-io/milvus</guid>
    </item>
    <item>
      <title>microsoft/call-center-ai</title>
      <link>https://github.com/microsoft/call-center-ai</link>
      <description>&lt;p&gt;概要: 该文本介绍了一个基于Azure和OpenAI GPT的AI驱动的智能客服解决方案，允许通过API调用或预设电话号码发起语音通话，并支持多语言沟通、实时对话、数据收集与存储、自动提醒以及自定义配置，适用于保险、IT支持等多个领域，旨在提供24/7服务，提升客户体验和运营效率。&lt;/p&gt;  
&lt;h3&gt;核心要点:&lt;/h3&gt;  
&lt;ul&gt;  
  &lt;li&gt;&lt;strong&gt;AI驱动的呼叫中心&lt;/strong&gt;：使用Azure和OpenAI GPT构建，支持语音、短信和多语言交互，提供24/7服务，适应低到中等复杂度的客户服务需求。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;高度定制化能力&lt;/strong&gt;：支持自定义数据结构、任务配置、语言设置、语音风格及调用流程，满足不同业务场景的具体需求。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;集成与扩展性&lt;/strong&gt;：采用容器化、无服务器架构部署，支持与Azure多个服务集成，如通信服务、认知服务、AI搜索等，便于快速迭代和扩展。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;智能与合规处理&lt;/strong&gt;：使用gpt-4.1和gpt-4.1-nano模型，结合RAG技术进行数据检索，支持敏感信息处理并符合数据隐私和安全规范。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;监控与成本优化&lt;/strong&gt;：内置Azure Application Insights监控体系，提供详细的性能指标和日志；支持按需扩展资源，优化运营成本。&lt;/li&gt;  
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/microsoft/call-center-ai</guid>
    </item>
  </channel>
</rss>