<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>GitHub-Scala</title>
    <link>https://mshibanami.github.io/GitHubTrendingRSS/daily/scala.xml</link>
    <description>Summarized RSS feed for GitHub-Scala</description>
    <atom:link href="https://mshibanami.github.io/GitHubTrendingRSS/daily/scala.xml" rel="self" type="application/rss+xml"/>
    <item>
      <title>gitbucket/gitbucket</title>
      <link>https://github.com/gitbucket/gitbucket</link>
      <description>&lt;p&gt;概要: GitBucket是一款基于Scala构建的轻量级Git平台，具备易安装、高扩展性与GitHub API兼容性等核心优势，提供公私仓库管理、GitLFS支持、在线文件编辑、Issue与Pull Request协作功能及LDAP账户管理，同时通过插件系统支持多功能扩展，但需注意H2数据库在版本升级时的迁移要求，以确保系统稳定运行。&lt;/p&gt;  
&lt;h3&gt;核心要点:&lt;/h3&gt;  
&lt;ul&gt;  
&lt;li&gt;&lt;strong&gt;平台基础与核心优势&lt;/strong&gt;: 采用Scala开发，支持易安装、高扩展性及GitHub API兼容性，确保与主流Git工具无缝集成。&lt;/li&gt;  
&lt;li&gt;&lt;strong&gt;核心功能覆盖&lt;/strong&gt;: 包含公私仓库（支持HTTP/HTTPS和SSH）、GitLFS、在线文件编辑、Issue追踪、Pull Request及Wiki，满足开发协作需求。&lt;/li&gt;  
&lt;li&gt;&lt;strong&gt;数据库迁移要求&lt;/strong&gt;: 升级至4.43及以上版本需手动迁移H2数据库至v2版本，涉及导出与重建数据库的具体操作步骤。&lt;/li&gt;  
&lt;li&gt;&lt;strong&gt;插件扩展生态&lt;/strong&gt;: 内置官方插件（如Gist、Emoji、Pages、Notifications）并支持社区开发插件，提升功能灵活性。&lt;/li&gt;  
&lt;li&gt;&lt;strong&gt;支持与版本策略&lt;/strong&gt;: 优先保障安装便捷性和GitHub兼容性，可能拒绝与该原则冲突的请求，需通过Wiki或Gitter渠道获取支持。&lt;/li&gt;  
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/gitbucket/gitbucket</guid>
    </item>
    <item>
      <title>NVIDIA/spark-rapids</title>
      <link>https://github.com/NVIDIA/spark-rapids</link>
      <description>&lt;p&gt;概要: RAPIDS Accelerator for Apache Spark 是一个利用 GPU 加速 Apache Spark 处理的插件集，通过 RAPIDS 库实现性能提升，提供兼容性、调优、配置、问题反馈、下载及集成等功能，旨在帮助用户高效地在 GPU 环境中运行大数据处理任务。&lt;/p&gt;

&lt;h3&gt;核心要点:&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;GPU 加速处理&lt;/strong&gt;: RAPIDS Accelerator for Apache Spark 通过 GPU 提升 Apache Spark 的数据处理性能。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;兼容性保障&lt;/strong&gt;: SQL 插件旨在与 Apache Spark 保持完全兼容，确保结果一致。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;集成零拷贝数据传输&lt;/strong&gt;: 提供 API 实现与其他 GPU 启用应用的零拷贝数据传输，尤其与 XGBoost 有集成计划。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;依赖管理建议&lt;/strong&gt;: 对于外部项目开发，建议使用提供的依赖项来确保与 RAPIDS 插件的兼容性和性能优化。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;资源管理注意事项&lt;/strong&gt;: 导出数据至 ML 库时需考虑禁用 RMM 缓存以避免内存冲突。&lt;/li&gt;
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/NVIDIA/spark-rapids</guid>
    </item>
    <item>
      <title>chipsalliance/rocket-chip</title>
      <link>https://github.com/chipsalliance/rocket-chip</link>
      <description>&lt;p&gt;概要: Rocket Chip Generator 是一个用于生成和测试完整 RISC-V Rocket 核心 SoC 的元仓库，包含多个 Git 子模块和 Scala 包，支持通过 Chisel 生成 RTL，并提供多种工具和资源用于仿真、调试和构建，同时也支持通过 IntelliJ 和 VSCode 等 IDE 进行开发。&lt;/p&gt;

&lt;h3&gt;核心要点:&lt;/h3&gt;  
&lt;ul&gt;  
  &lt;li&gt;&lt;strong&gt; Rocket Chip Generator 是一个元仓库，集成多个子模块和 Scala 包，用于生成和测试 RISC-V Rocket 核心的 SoC 设计。&lt;/strong&gt;&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt; 该工具链基于 Chisel 和 Firrtl 进行 RTL 生成，支持高性能硬件设计和验证。&lt;/strong&gt;&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt; 提供多种开发和测试资源，包括 Verilator、VCS 仿真环境、BootROM、C 源码以及自动化的回归测试框架。&lt;/strong&gt;&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt; 支持通过 BSP 配置和 IDE 工具（如 IntelliJ 和 VSCode）提升开发效率和集成能力。&lt;/strong&gt;&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt; 项目由 UC Berkeley 的多个研究人员共同维护，具有明确的贡献指南和技术报告可供引用。&lt;/strong&gt;&lt;/li&gt;  
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/chipsalliance/rocket-chip</guid>
    </item>
    <item>
      <title>playframework/playframework</title>
      <link>https://github.com/playframework/playframework</link>
      <description>&lt;p&gt;概要: Play Framework 是一个专为 Java 和 Scala 开发者设计的高效、现代的 Web 框架，结合了开发效率与性能优势，通过“只需刷新”工作流和内置测试支持提升开发体验，采用非阻塞和无状态架构确保应用可预测地扩展，同时默认支持 REST、JSON 和 WebSocket，是构建现代 Web 和移动应用的理想选择。&lt;/p&gt;

&lt;h3&gt;核心要点:&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;支持 Java 和 Scala 开发&lt;/strong&gt;：Play Framework 适用于 Java 和 Scala 语言，提供统一的开发环境。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;开发效率与性能兼具&lt;/strong&gt;：以“只需刷新”方式简化开发流程，同时保证高性能和可扩展性。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;架构支持可预测的扩展性&lt;/strong&gt;：基于非阻塞、无状态架构，便于构建高性能、可扩展的 Web 应用。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;内置测试支持与开发友好&lt;/strong&gt;：提供测试工具和流畅的开发体验，加快开发与调试过程。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;默认支持 RESTful 设计&lt;/strong&gt;：内置 JSON 和 WebSocket 支持，适应现代 Web 和移动应用需求。&lt;/li&gt;
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/playframework/playframework</guid>
    </item>
    <item>
      <title>apache/spark</title>
      <link>https://github.com/apache/spark</link>
      <description>&lt;p&gt;概要: Apache Spark 是一个统一的大规模数据分析引擎，提供多种高级编程接口（如 Scala、Java、Python 和 R），并集成丰富的工具组件，如 Spark SQL、MLlib、GraphX 和 Structured Streaming，支持高效的数据处理、机器学习、图计算和流式计算任务。&lt;/p&gt;

&lt;h3&gt;核心要点:&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;统一的数据分析引擎&lt;/strong&gt;：支持大规模数据处理，整合多种计算模式。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;多语言 API 支持&lt;/strong&gt;：提供 Scala、Java、Python 和 R（已弃用）的高阶接口。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;支持多种数据处理工具&lt;/strong&gt;：涵盖 SQL、机器学习、图计算和流处理等高级功能。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;构建与部署灵活性&lt;/strong&gt;：可以通过 Maven 构建，也可使用预构建包；支持本地、YARN 和 Kubernetes 等多种运行环境。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;需适配 Hadoop 版本&lt;/strong&gt;：Spark 依赖 Hadoop 核心库，必须与集群运行的 Hadoop 版本一致。&lt;/li&gt;
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/apache/spark</guid>
    </item>
    <item>
      <title>scala/scala</title>
      <link>https://github.com/scala/scala</link>
      <description>&lt;p&gt;概要: 本文详细说明了Scala 2的贡献流程、分支策略、仓库结构及构建规范，强调需通过GitHub提交PR并遵循严格的版本兼容性规则（如仅允许修改现有代码而非新增标准库内容），同时提供CI自动化测试、社区构建验证及开发工具配置指南，以确保代码贡献符合项目维护标准并有效支持Scala的持续集成与版本迭代。&lt;/p&gt;  
&lt;h3&gt;核心要点:&lt;/h3&gt;  
&lt;ul&gt;  
  &lt;li&gt;&lt;strong&gt;贡献流程&lt;/strong&gt;: 提交PR需基于fork的仓库，针对2.13.x主分支（特殊情况可选2.12.x），并需签署Scala CLA。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;版本兼容性限制&lt;/strong&gt;: 标准库仅允许修改现有代码，新增功能需提交至scala-library-next；需通过[bin/pre]后缀区分二进制兼容性。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;CI测试机制&lt;/strong&gt;: 提交PR后触发自动测试，支持/rebuild指令重建失败任务，社区构建可提前验证代码对开源项目的兼容性。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;构建与调试工具&lt;/strong&gt;: 需安装Java SDK 8+和sbt，支持MacOS/Linux，推荐使用IntelliJ或VSCode/Metals进行IDE开发，需注意STARR与bootstrap流程。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;仓库结构规范&lt;/strong&gt;: 核心代码位于src/library/compiler等目录，测试文件分JUnit、ScalaCheck、partest类型，构建产物存于build/dist/target等路径。&lt;/li&gt;  
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/scala/scala</guid>
    </item>
    <item>
      <title>delta-io/delta-sharing</title>
      <link>https://github.com/delta-io/delta-sharing</link>
      <description>&lt;p&gt;概要: Delta Sharing 是一个开放的协议，支持在不同计算平台上进行安全的实时大规模数据共享，允许用户通过多种工具（如 pandas、Apache Spark）直接访问共享数据，而无需部署特定计算环境。该协议利用现代云存储系统如 S3、ADLS 和 GCS 实现可靠的数据传输，并提供丰富的配置选项以支持多种云存储和身份验证方式，同时支持变更数据捕获（CDF）和流式处理功能，便于开发和测试。&lt;/p&gt;

&lt;h3&gt;核心要点:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Delta Sharing 是一个开放、安全的实时数据共享协议&lt;/strong&gt;，适用于多种云存储格式，支持跨平台访问。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;支持多种编程语言和工具&lt;/strong&gt;，包括 Python、Apache Spark、SQL、Java、Scala、R 和 others，便于灵活集成。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;提供多种配置方式以支持不同的云存储系统&lt;/strong&gt;，如 S3、Azure Blob Storage、GCS 和 Cloudflare R2，允许自定义认证和连接设置。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;支持变更数据捕获（CDF）和流式处理功能&lt;/strong&gt;，从版本 0.5.0 和 0.6.0 开始分别加入对 CDF 和 Spark Structured Streaming 的支持。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;提供参考实现和 Docker 部署方案&lt;/strong&gt;，便于快速搭建和测试 Delta Sharing 服务器。&lt;/li&gt;
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/delta-io/delta-sharing</guid>
    </item>
    <item>
      <title>chipsalliance/chisel</title>
      <link>https://github.com/chipsalliance/chisel</link>
      <description>&lt;p&gt;概要: Chisel是一款基于Scala的开源硬件描述语言（HDL），通过集成现代编程语言特性，支持参数化电路生成与设计复用，显著提升ASIC和FPGA设计的抽象层级同时保持精细控制，其底层依赖LLVM CIRCT实现的FIRRTL框架，并采用Apache 2.0许可证，提供丰富的文档资源和社区支持，助力高效硬件开发与验证。&lt;/p&gt;  
&lt;h3&gt;核心要点:&lt;/h3&gt;  
&lt;ul&gt;  
  &lt;li&gt;&lt;strong&gt;Scala集成与参数化设计&lt;/strong&gt;: 通过Scala语言特性实现硬件构造，支持复杂、可参数化的电路生成器，如FIFO队列和仲裁器，增强设计复用性。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;FIRRTL作为核心框架&lt;/strong&gt;: 基于LLVM CIRCT实现的FIRRTL（灵活RTL中间表示）负责电路编译与转换，确保生成代码的可综合性和跨工具兼容性。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;灵活版本管理策略&lt;/strong&gt;: 用户推荐使用最新稳定版，开发者则需依赖SNAPSHOT版本，且需注意其API/ABI不兼容性风险。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;全面验证工具链&lt;/strong&gt;: 提供svsim轻量测试库、chiseltest集成验证框架及Verilator/VCS仿真支持，覆盖从单元测试到形式验证的全流程。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;模块化架构与贡献指南&lt;/strong&gt;: 包含核心、FIRRTL、宏库等子项目，明确代码归属规范，并提供本地构建与测试的详细流程。&lt;/li&gt;  
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/chipsalliance/chisel</guid>
    </item>
    <item>
      <title>TheHive-Project/TheHive</title>
      <link>https://github.com/TheHive-Project/TheHive</link>
      <description>&lt;p&gt;概要: TheHive 3和4.x版本已于2023年起停止维护、分发和公开访问，相关GitHub仓库已被归档，用户需转向最新商业版本以获取持续支持与更新，同时可联系官方获取迁移协助。&lt;/p&gt;  
&lt;h3&gt;核心要点:&lt;/h3&gt;  
&lt;ul&gt;  
  &lt;li&gt;&lt;strong&gt;TheHive 3和4.x版本已停用&lt;/strong&gt;：不再维护、分发或公开获取。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;官方转向商业版本&lt;/strong&gt;：为确保安全性和持续支持，TheHive现作为商业产品分发。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;迁移支持可联系官方获取&lt;/strong&gt;：现有用户如需帮助迁移至新版本，可通过指定邮箱或官网联系。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;新版本功能更完善&lt;/strong&gt;：增强性能、安全性和适配现代SOC操作的新功能。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;官网与文档为获取信息渠道&lt;/strong&gt;：建议用户访问官方链接获取详细信息与支持。&lt;/li&gt;  
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/TheHive-Project/TheHive</guid>
    </item>
    <item>
      <title>OpenXiangShan/XiangShan</title>
      <link>https://github.com/OpenXiangShan/XiangShan</link>
      <description>&lt;p&gt;概要: 香山（XiangShan）是一个开源的高性能RISC-V处理器项目，采用敏捷开发方法加速芯片设计与验证流程，包含多个稳定架构版本及开发分支，并提供了详细的文档、工具链支持和多语言翻译，鼓励社区参与改进与创新。&lt;/p&gt;  
&lt;h3&gt;核心要点:&lt;/h3&gt;  
&lt;ul&gt;  
  &lt;li&gt;&lt;strong&gt;香山是开源的高性能RISC-V处理器项目&lt;/strong&gt;，旨在推动RISC-V生态发展，支持敏捷开发方法以提升设计效率。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;项目包含多个稳定架构版本&lt;/strong&gt;，如Yanqihu（雁栖湖）、Nanhu（南湖）和Kunminghu（昆明湖），其中Kunminghu仍在开发中。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;提供完整的文档支持&lt;/strong&gt;，包括设计文档、用户指南，并支持多语言翻译，欢迎社区贡献。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;支持多种仿真与运行方式&lt;/strong&gt;，包括使用Verilator构建C++模拟器和通过xspdb进行Python二进制调试。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;采用Mulan PSL v2许可协议&lt;/strong&gt;，由中科院、北京开源芯片研究院和鹏城实验室联合授权。&lt;/li&gt;  
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/OpenXiangShan/XiangShan</guid>
    </item>
    <item>
      <title>ucb-bar/chipyard</title>
      <link>https://github.com/ucb-bar/chipyard</link>
      <description>&lt;p&gt;概要: Chipyard 是一个开源的敏捷RISC-V系统芯片设计框架，集成了Chisel硬件描述语言、Rocket Chip SoC生成器及其他伯克利项目，支持从基础外设到定制加速器的完整SoC开发。该框架涵盖多种处理器核心、向量单元、加速器、内存系统及外围设备，同时提供软件RTL仿真、FPGA加速仿真、自动化VLSI流程和软件工作负载生成等多并发开发功能，由加州大学伯克利分校的Berkeley架构研究小组持续开发。&lt;/p&gt;

&lt;h3&gt;核心要点:&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Chipyard 是一个开源框架&lt;/strong&gt;，用于敏捷开发基于Chisel的RISC-V系统芯片，整合了多种硬件组件和工具链。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;支持多种处理器架构和加速器&lt;/strong&gt;，包括Rocket、BOOM、CVA6、Gemmini、NVDLA等，适用于不同性能和功能需求的SoC设计。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;集成多个开发与仿真工具&lt;/strong&gt;，如FireSim、FireMarshal、Hammer等，支持从RTL仿真到FPGA加速和自动化实现的全流程。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;提供完整的开发资源和社区支持&lt;/strong&gt;，包括文档、教程、演示幻灯片、问答论坛以及贡献指南。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;由加州大学伯克利分校的Berkeley架构研究小组主导开发&lt;/strong&gt;，并获得NSF资助，具有较强的学术与工程背景支持。&lt;/li&gt;
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/ucb-bar/chipyard</guid>
    </item>
    <item>
      <title>scala/scala3</title>
      <link>https://github.com/scala/scala3</link>
      <description>&lt;p&gt;概要: Scala 3编译器Dotty提供了完整的文档资源、本地构建指南及贡献规范，支持通过Getting Started User Guide快速集成至项目，并遵循Apache License Version 2.0开源协议，其社区沟通标准统一采用Scala行为准则。&lt;/p&gt;  
&lt;h3&gt;核心要点:&lt;/h3&gt;  
&lt;ul&gt;  
  &lt;li&gt;&lt;strong&gt;构建方式&lt;/strong&gt;: 通过`sbt dist/Universal/packageBin`命令生成本地分发包，存于`dist/target/`目录。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;开源协议&lt;/strong&gt;: 采用Apache License Version 2.0授权，明确代码使用与分发的法律框架。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;贡献流程&lt;/strong&gt;: 提供贡献者入门指南，规范了问题报告、代码提交及社区互动的全流程。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;社区规范&lt;/strong&gt;: 统一适用Scala行为准则，覆盖GitHub、Discord及邮件等所有沟通渠道。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;文档与试用&lt;/strong&gt;: 拥有系统性文档支持，并通过用户指南简化了在实际项目中的试用步骤。&lt;/li&gt;  
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/scala/scala3</guid>
    </item>
    <item>
      <title>lichess-org/lila</title>
      <link>https://github.com/lichess-org/lila</link>
      <description>&lt;p&gt;概要: Lichess 是一个完全免费、无广告、开源的在线国际象棋服务器，专注于实时对弈与用户体验，支持多种功能如比赛、战术训练、论坛及多语言界面，并采用先进的技术栈构建，包括 Scala 3、Play 框架、MongoDB 和 Elasticsearch，同时提供开放的 API 和完善的开发者支持。&lt;/p&gt;

&lt;h3&gt;核心要点:&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;完全免费、无广告、开源&lt;/strong&gt;：Lichess 提供开放、透明的平台，所有功能均为免费且不包含广告。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;强大的功能集&lt;/strong&gt;：支持实时对弈、搜索、战术训练、比赛、论坛、团队协作、移动应用等多种用户交互功能。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;多语言支持&lt;/strong&gt;：用户界面支持超过 140 种语言，增强全球用户的可访问性。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;高性能架构&lt;/strong&gt;：采用异步设计，基于 Scala Futures 和 Akka Streams，同时集成 Redis、Stockfish 和 Elasticsearch 提升性能与数据处理能力。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;开放 API 与开发者生态&lt;/strong&gt;：提供 HTTP API 供外部应用调用，并鼓励通过 GitHub 和 Discord 参与开发与反馈。&lt;/li&gt;
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/lichess-org/lila</guid>
    </item>
    <item>
      <title>sbt/sbt</title>
      <link>https://github.com/sbt/sbt</link>
      <description>&lt;p&gt;概要: sbt（Scala Build Tool）是一款支持Scala、Java及其他语言的交互式构建工具，其2.x版本源代码分散在多个GitHub仓库中，包括核心功能实现、增量编译器Zinc及特定模块如sbt.io。用户可通过官方文档获取基础信息，在遇到问题时优先参考StackOverflow或遵循CONTRIBUTING指南提交反馈，旧版本（0.7.7及之前）存于独立仓库，许可证信息详见LICENSE文件。&lt;/p&gt;  
&lt;h3&gt;核心要点:&lt;/h3&gt;  
&lt;ul&gt;  
  &lt;li&gt;&lt;strong&gt;多语言支持&lt;/strong&gt;: 专为Scala、Java设计，兼容其他编程语言的构建需求。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;模块化代码结构&lt;/strong&gt;: 2.x版本源代码分拆至sbt/io（sbt.io模块）、sbt/zinc（Zinc增量编译器）及sbt/sbt（核心工具实现）等独立仓库。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;版本管理差异&lt;/strong&gt;: 旧版sbt（0.7.7及更早）单独托管于sbt/sbt-zero-seven仓库。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;社区支持渠道&lt;/strong&gt;: 问题排查优先通过StackOverflow，正式反馈需遵循CONTRIBUTING指南提交至GitHub。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;开源授权信息&lt;/strong&gt;: 开源协议及许可条款详见LICENSE文件。&lt;/li&gt;  
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/sbt/sbt</guid>
    </item>
    <item>
      <title>twitter/the-algorithm</title>
      <link>https://github.com/twitter/the-algorithm</link>
      <description>&lt;p&gt;概要: X的推荐算法是一个集成多服务和模型的系统，通过共享数据层、模型层及软件框架支撑包括For You Timeline、Search、Explore、Notifications在内的所有产品内容分发。系统采用混合候选源和分层排名机制，结合实时用户行为追踪与社区检测技术，同时通过开放源代码和社区协作提升算法质量与安全性，未来将完善构建测试体系。  
&lt;/p&gt;  
&lt;h3&gt;核心要点:&lt;/h3&gt;  
&lt;ul&gt;  
  &lt;li&gt;&lt;strong&gt;模块化架构&lt;/strong&gt;: 系统由数据层（如tweetypie、user-signal-service）、模型层（SimClusters、TwHIN、trust-and-safety-models）及软件框架（navi、product-mixer、twml）构成，实现跨产品表面的统一内容推荐。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;For You Timeline机制&lt;/strong&gt;: 候选源包含50%的In-Network内容（search-index）及Out-of-Network内容（tweet-mixer），通过light-ranker与heavy-ranker分层排序，结合UTEG的实时交互图谱进行个性化推荐。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;Recommended Notifications模型&lt;/strong&gt;: 采用pushservice作为核心推荐服务，通过轻量级过滤模型（pushservice-light-ranker）和多任务学习模型（pushservice-heavy-ranker）预测用户通知打开率及互动概率。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;构建与测试现状&lt;/strong&gt;: 当前仅提供组件级Bazel构建文件，缺少顶层构建体系，计划未来扩展更完整的测试与管理功能。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;社区贡献与安全协作&lt;/strong&gt;: 鼓励通过GitHub提交改进建议，安全问题需通过HackerOne官方漏洞计划反馈，强调开放源代码对产品迭代与风险控制的价值。&lt;/li&gt;  
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/twitter/the-algorithm</guid>
    </item>
    <item>
      <title>delta-io/delta</title>
      <link>https://github.com/delta-io/delta</link>
      <description>&lt;p&gt;概要: Delta Lake 是一个开源存储框架，支持构建 Lakehouse 架构，并兼容多种计算引擎如 Spark、PrestoDB、Flink、Trino 和 Hive，提供 Scala、Java、Rust、Ruby 和 Python 多语言 API，确保数据的一致性、可靠性和并发处理能力。&lt;/p&gt;  
&lt;h3&gt;核心要点:&lt;/h3&gt;  
&lt;ul&gt;  
  &lt;li&gt;&lt;strong&gt;支持多种计算引擎和多语言 API&lt;/strong&gt;：Delta Lake 提供对 Spark、PrestoDB、Flink、Trino 和 Hive 的集成，并支持 Scala、Java、Rust、Ruby 和 Python 的 API 访问。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;Delta Standalone 实现单节点读写&lt;/strong&gt;：该库是一个基于 Java 的单节点实现，允许 Scala 和 Java 项目直接读写 Delta Lake 表，且通过事务日志协议保证事务性。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;确保向后兼容但可能破坏向前兼容&lt;/strong&gt;：Delta Lake 保证新版本可读旧版本生成的表，但新功能可能影响旧版本对新表的兼容性。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;ACID 保证依赖底层存储系统&lt;/strong&gt;：底层存储需满足原子可见性、互斥写入和一致性目录列出等要求，以确保 Delta Lake 的 ACID 属性。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;社区与贡献机制完善&lt;/strong&gt;：Delta Lake 拥有活跃社区支持，通过 GitHub Issues 报告问题，鼓励贡献，并遵循 Apache License 2.0 协议。&lt;/li&gt;  
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/delta-io/delta</guid>
    </item>
    <item>
      <title>digital-asset/daml</title>
      <link>https://github.com/digital-asset/daml</link>
      <description>&lt;p&gt;概要: Daml 是一种专为金融行业设计的高级智能合约语言，提供了一种安全、高效且易于理解的方式来开发和部署去中心化应用的合约逻辑，其完整文档可查看 sdk/README.md。&lt;/p&gt;  
&lt;h3&gt;核心要点:&lt;/h3&gt;  
&lt;ul&gt;  
  &lt;li&gt;&lt;strong&gt;Daml 专为金融行业设计&lt;/strong&gt;，强调安全性和合规性。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;提供高级语言特性&lt;/strong&gt;，提升开发效率与合约逻辑的可读性。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;支持去中心化应用开发&lt;/strong&gt;，便于构建信任自动化系统。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;文档详尽&lt;/strong&gt;，通过 sdk/README.md 提供全面的参考资料。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;注重合约执行的确定性和可靠性&lt;/strong&gt;，降低操作风险。&lt;/li&gt;  
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/digital-asset/daml</guid>
    </item>
    <item>
      <title>apache/incubator-gluten</title>
      <link>https://github.com/apache/incubator-gluten</link>
      <description>&lt;p&gt;概要: Apache Gluten 是一个旨在将 Apache Spark 的 JVM 基础 SQL 引擎执行任务卸载到原生引擎（如 ClickHouse 和 Velox）的中间层，通过将 Spark 物理计划转换为 Substrait 格式、复用分布式控制流、管理 JVM 与原生数据交互及定义 JNI 接口，实现性能提升与跨引擎兼容性，目前已在 Apache Incubator 中孵化，并支持多版本 Spark 集成。&lt;/p&gt;  
&lt;h3&gt;核心要点:&lt;/h3&gt;  
&lt;ul&gt;  
&lt;li&gt;&lt;strong&gt;性能优化核心&lt;/strong&gt;: 通过将计算密集型任务卸载至原生引擎，实现 Velox 后端单查询最高 14.53 倍、整体 2.71 倍的速度提升，ClickHouse 后端单查询最高 3.48 倍加速。&lt;/li&gt;  
&lt;li&gt;&lt;strong&gt;跨引擎兼容性设计&lt;/strong&gt;: 基于 Substrait 标准实现 Spark 物理计划到原生引擎的转换，支持多版本 Spark（3.2-3.5）及未来扩展性，通过 Shim 层确保版本适配。&lt;/li&gt;  
&lt;li&gt;&lt;strong&gt;无缝集成与配置&lt;/strong&gt;: 作为 Spark 插件无需修改 DataFrame API，仅需配置参数即可启用，支持通过预发布 JAR 或源码构建，适应不同操作系统环境。&lt;/li&gt;  
&lt;li&gt;&lt;strong&gt;数据格式与内存管理&lt;/strong&gt;: 采用 Apache Arrow 作为底层数据格式，实现列式数据交换（Columnar Shuffle）及统一的原生内存管理，优化数据传输效率。&lt;/li&gt;  
&lt;li&gt;&lt;strong&gt;社区与生态支持&lt;/strong&gt;: 由 Intel 和 Kyligence 于 2022 年发起，获得 Microsoft、IBM、Google 等多家企业的贡献，已进入 Apache Incubator 并提供多语言协作渠道（GitHub、Slack、WeChat）。&lt;/li&gt;  
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/apache/incubator-gluten</guid>
    </item>
    <item>
      <title>ucb-bar/riscv-torture</title>
      <link>https://github.com/ucb-bar/riscv-torture</link>
      <description>&lt;p&gt;概要: RISC-V Torture Test 是一个用于验证 RISC-V 指令集架构实现正确性的测试生成与执行框架，包含三个子项目：生成随机测试、运行测试并对比模拟器输出、以及长期自动运行测试。通过比较不同模拟器产生的寄存器状态签名，可以快速定位潜在的实现错误。&lt;/p&gt;  
&lt;h3&gt;核心要点:&lt;/h3&gt;  
&lt;ul&gt;  
  &lt;li&gt;&lt;strong&gt;框架结构&lt;/strong&gt;：包含生成器（generator）、测试运行器（testrun）和长期测试工具（overnight）三个子项目，分别用于测试生成、执行与比对、以及自动化持续测试。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;签名机制&lt;/strong&gt;：测试通过记录寄存器状态生成签名文件，与 ISA 模拟器（如 Spike）结果对比，以检测硬件实现是否正确。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;虚拟寄存器概念&lt;/strong&gt;：区分隐藏寄存器（位置相关）和可见寄存器（位置无关），仅可见寄存器用于输出签名以确保一致性。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;测试生成方式&lt;/strong&gt;：基于手工编写的测试序列，进行随机指令调度与寄存器分配，提高覆盖率与随机性。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;自动化与扩展性&lt;/strong&gt;：overnight 工具可设置运行时长与失败阈值，支持自动报告和失败记录；框架支持通过 Scala 扩展测试序列及功能。&lt;/li&gt;  
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/ucb-bar/riscv-torture</guid>
    </item>
    <item>
      <title>apache/incubator-livy</title>
      <link>https://github.com/apache/incubator-livy</link>
      <description>&lt;p&gt;概要: Apache Livy 是一个开源的 REST 接口，允许通过任意平台与 Apache Spark 交互，支持代码片段或程序的执行、多语言（Scala/Python/R）交互式shell及批量任务提交，具备多用户共享服务器能力与版本兼容性，且无需修改现有程序即可集成，提供灵活的构建配置与文档资源，是 Spark 应用开发与运维的高效桥梁。&lt;/p&gt;  
&lt;h3&gt;核心要点:&lt;/h3&gt;  
&lt;ul&gt;  
  &lt;li&gt;&lt;strong&gt;跨平台无代码交互&lt;/strong&gt;：通过 REST 接口支持从任何位置向 Spark 集群提交代码或程序，无需修改原有代码。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;多语言与多模式支持&lt;/strong&gt;：提供 Scala、Python 和 R 的交互式shell，兼容本地运行及 YARN 分布式环境。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;版本灵活适配&lt;/strong&gt;：支持运行时切换 Spark 版本（3.0+）并通过构建配置选择依赖版本（如 Hadoop2/Spark3/Scala2.12），无需重建项目。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;共享与安全机制&lt;/strong&gt;：允许多用户共享同一服务器实例，内置身份伪装（impersonation）功能以保障权限管理。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;构建便捷性&lt;/strong&gt;：提供 Maven 和 Docker 构建方式，支持自定义依赖缓存以加速重复构建过程。&lt;/li&gt;  
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/apache/incubator-livy</guid>
    </item>
    <item>
      <title>hyperledger-labs/splice</title>
      <link>https://github.com/hyperledger-labs/splice</link>
      <description>&lt;p&gt;概要: Splice 是一组参考应用程序，旨在为基于 Daml 平台的公共、去中心化 Canton 同步器提供资金、运营和激励机制，通过 Amulet 等应用实现链上支付与奖励分配，构建透明且可持续的经济生态，推动多节点间的安全、有序状态同步与交易处理。&lt;/p&gt;  
&lt;h3&gt;核心要点:&lt;/h3&gt;  
&lt;ul&gt;  
  &lt;li&gt;&lt;strong&gt;Splice 提供去中心化 Canton 同步器的运营、治理与激励机制&lt;/strong&gt;，支持应用开发者在透明环境中部署和使用区块链状态同步服务。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;Amulet 是 Splice 的核心支付工具&lt;/strong&gt;，通过“amulet”实现基于数据量的链上支付，并可作为激励手段用于早期用户和同步器运营者。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;Splice 基于 Daml 平台构建，支持隐私保护与状态同步&lt;/strong&gt;，并通过治理应用实现对同步器费用、货币兑换率及发行机制的管理。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;Splice 构建了一个开放的经济激励体系&lt;/strong&gt;，包括流量获取工具、代币配置变量以及多方投票治理机制，提升网络采用率。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;Splice 仍在开源迁移过程中&lt;/strong&gt;，目前代码依赖于 Digital Asset 私有库，未来将独立部署并扩展其功能与社区协作。&lt;/li&gt;  
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/hyperledger-labs/splice</guid>
    </item>
  </channel>
</rss>