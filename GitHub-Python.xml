<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>GitHub-Python</title>
    <link>https://mshibanami.github.io/GitHubTrendingRSS/daily/python.xml</link>
    <description>Summarized RSS feed for GitHub-Python</description>
    <atom:link href="https://mshibanami.github.io/GitHubTrendingRSS/daily/python.xml" rel="self" type="application/rss+xml"/>
    <item>
      <title>yeongpin/cursor-free-vip</title>
      <link>https://github.com/yeongpin/cursor-free-vip</link>
      <description>&lt;p&gt;概要: 本工具旨在帮助用户绕过Cursor AI的免费试用限制，通过自动重置机器ID和提升Token限制，免费解锁Pro功能，适用于Windows、macOS和Linux系统，支持多语言操作，并提供详细的配置和使用说明，但仅限学习与研究用途，用户需遵守相关条款。&lt;/p&gt;

&lt;h3&gt;核心要点:&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;功能描述&lt;/strong&gt;: 自动重置Cursor AI机器ID，绕过试用限制，免费使用Pro功能。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;系统兼容性&lt;/strong&gt;: 支持Windows、macOS和Linux系统，涵盖多种架构。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;合法性声明&lt;/strong&gt;: 工具仅供学习与研究，不违反任何法律，且不会生成虚假邮件或OAuth凭据。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;使用与配置&lt;/strong&gt;: 提供自动化脚本安装方式，并包含详细的配置文件路径与参数设置。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;使用限制与注意事项&lt;/strong&gt;: 需管理员权限运行，确保Cursor已关闭，且禁止使用临时邮件服务。&lt;/li&gt;
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/yeongpin/cursor-free-vip</guid>
    </item>
    <item>
      <title>volcengine/MineContext</title>
      <link>https://github.com/volcengine/MineContext</link>
      <description>&lt;p&gt;概要: MineContext 是一款开源的上下文感知AI助手，专注于通过智能收集、呈现和主动推送用户数字环境中的信息，帮助用户提升工作效率、组织和创造能力，同时保障本地数据隐私与安全，支持多种LLM模型及多平台部署。&lt;/p&gt;

&lt;h3&gt;核心要点:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;本地优先与隐私保护&lt;/strong&gt;：所有数据默认存储于本地，确保用户隐私和数据安全，还支持自定义本地AI模型，防止数据外泄。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;多源多模态上下文采集&lt;/strong&gt;：通过截图、链接上传、文件监测、应用API集成等方式，全面捕捉用户的数字生活与工作环境信息。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;主动生成智能内容&lt;/strong&gt;：自动推送每日/每周摘要、任务清单、活动记录等，提升用户的决策效率与信息处理能力。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;开放源码与可定制性&lt;/strong&gt;：基于开源架构，允许开发者自由修改与扩展，相较于封闭的ChatGPT Pulse，具备更高的灵活性和透明度。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;跨平台与模块化结构&lt;/strong&gt;：前端采用Electron、React和TypeScript构建，后端具备清晰的分层架构设计，便于开发和维护。&lt;/li&gt;
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/volcengine/MineContext</guid>
    </item>
    <item>
      <title>GibsonAI/Memori</title>
      <link>https://github.com/GibsonAI/Memori</link>
      <description>&lt;p&gt;概要: Memori 是一个开源的 SQL 原生记忆引擎，为大型语言模型（LLMs）、AI 代理和多代理系统提供持久化、可查询的记忆存储，只需一行代码即可实现与主流 LLM 框架的集成，支持多种 SQL 数据库，具备智能记忆管理、显著成本节约及无厂商锁定的优势。&lt;/p&gt;

&lt;h3&gt;核心要点:&lt;/h3&gt;
&lt;ul&gt;
    &lt;li&gt;&lt;strong&gt;单行代码集成&lt;/strong&gt;：通过 memori.enable() 即可实现对任意 LLM 的记忆增强，支持 OpenAI、Anthropic、LiteLLM 等主流框架。&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;SQL 原生存储&lt;/strong&gt;：使用标准 SQL 数据库（如 PostgreSQL、MySQL、SQLite）进行记忆存储，确保可移植性、可审计性及可控性。&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;显著成本节约&lt;/strong&gt;：无需昂贵的向量数据库，节省高达 80-90% 的存储与计算成本。&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;智能记忆管理&lt;/strong&gt;：自动提取实体、建立关系并优化上下文优先级，支持背景分析与记忆迁移机制。&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;可扩展与兼容性强&lt;/strong&gt;：支持多用户、多代理系统及多种企业级框架集成，涵盖 LangChain、AutoGen、CrewAI 等，适用于企业场景。&lt;/li&gt;
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/GibsonAI/Memori</guid>
    </item>
    <item>
      <title>thinking-machines-lab/tinker-cookbook</title>
      <link>https://github.com/thinking-machines-lab/tinker-cookbook</link>
      <description>&lt;p&gt;概要: Tinker 是一个为研究者和开发者提供语言模型微调能力的训练 SDK，用户可通过 API 请求进行分布式训练，而无需处理底层复杂性；同时，Tinker Cookbook 提供了多种微调方法的实战示例与高级抽象，涵盖监督学习、强化学习、偏好学习、工具使用、提示蒸馏与多智能体训练，助力用户快速构建和优化定制化训练环境。&lt;/p&gt;

&lt;h3&gt;核心要点:&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Tinker 和 Tinker Cookbook 是两个互补的工具库&lt;/strong&gt;，前者专注于训练 SDK，后者提供多种微调范式的实战示例与高级抽象。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;用户只需发送 API 请求&lt;/strong&gt;，Tinker 自动处理分布式训练的复杂性，降低使用门槛。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Tinker Cookbook 包含多种微调技术的示例&lt;/strong&gt;，如监督学习、强化学习、偏好学习及多智能体训练等，适用于不同应用场景。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;提供实用工具和评估抽象&lt;/strong&gt;，帮助用户处理 tokens、计算 LoRA 超参数，并方便地与标准评估基准对接。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;项目鼓励社区贡献&lt;/strong&gt;，在私有测试阶段结束后接受 PR，持续推动开源协作与模型优化。&lt;/li&gt;
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/thinking-machines-lab/tinker-cookbook</guid>
    </item>
    <item>
      <title>Zie619/n8n-workflows</title>
      <link>https://github.com/Zie619/n8n-workflows</link>
      <description>&lt;p&gt;概要: n8n Workflow Collection 是一个集成大量自动化工作流的开源项目，包含4,343个可用的生产级工作流和365个独特集成，提供快速搜索、分类浏览、移动兼容和直接下载功能，同时支持本地和Docker部署，具备增强的安全性与高性能表现。&lt;/p&gt;

&lt;h3&gt;核心要点:&lt;/h3&gt;
&lt;ul&gt;
    &lt;li&gt;&lt;strong&gt;高性能与优化搜索&lt;/strong&gt;: 采用SQLite FTS5提升搜索速度至100ms以内，内存占用低于50MB，且整体体积比v1小700倍。&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;全面增强的安全性&lt;/strong&gt;: 完成完整安全审计，修复所有CVE漏洞，支持路径遍历防护、输入验证、CORS保护、速率限制以及非root容器用户等安全机制。&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;现代化用户界面&lt;/strong&gt;: 提供完全重新设计的界面，支持深色/浅色模式，提升用户体验。&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;多平台部署支持&lt;/strong&gt;: 支持本地安装与Docker部署，满足不同环境下的使用需求。&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;丰富的功能与细节&lt;/strong&gt;: 提供超过15个分类、365个集成、29,445个节点，确保工作流的多样性和可导入性，且导入成功率100%。&lt;/li&gt;
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/Zie619/n8n-workflows</guid>
    </item>
    <item>
      <title>MustardChef/WSABuilds</title>
      <link>https://github.com/MustardChef/WSABuilds</link>
      <description>&lt;p&gt;概要: 该文本介绍了如何在Windows 10和Windows 11上使用Windows Subsystem for Android (WSA)的预构建版本，支持安装Google Play Store和Magisk或KernelSU以实现root功能。然而，近期的Windows更新导致许多WSA安装失效，提供了一些工作绕过方法，同时列出了当前稳定版本及不同版本的兼容性状态，并针对特定应用和游戏给出了其在WSA上的可用性和常见问题。此外，文本还提供了WSA的安装、更新、卸载、备份及故障排查指南，强调了对系统配置、虚拟化、存储格式等要求，并提及项目对其独立性、法律声明及开源协议。&lt;/p&gt;

&lt;h3&gt;核心要点:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Windows更新导致WSA安装问题&lt;/strong&gt;: 近期更新破坏了多个WSA版本，建议使用旧版（如2211/2210）或避免包含Google应用的构建。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;提供LTS及非LTS版本&lt;/strong&gt;: 项目进入长期支持阶段，从WSA 2311.40000.5.0开始，Magisk、KernelSU和GApps会持续更新以提升稳定性。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;自定义构建需求&lt;/strong&gt;: 如果所需构建未提供，用户可请求定制版本，需在GitHub上提交具体需求如设备型号、是否需要root和GApps等。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;系统要求&lt;/strong&gt;: 需要特定Windows版本、至少8GB RAM、支持虚拟化的CPU，以及NTFS格式的存储分区，某些GPU（如Intel HD 530及以下，Nvidia系列）可能存在兼容问题。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;常见问题及解决&lt;/strong&gt;: 要特别注意应用兼容问题、权限设置、以及窗口大小对应用表现的影响，针对部分应用提供具体的解决方法如手动授予权限、检查网络设置等。&lt;/li&gt;
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/MustardChef/WSABuilds</guid>
    </item>
    <item>
      <title>google/adk-python</title>
      <link>https://github.com/google/adk-python</link>
      <description>&lt;p&gt;概要: Agent Development Kit (ADK) 是一个开源、代码优先的 Python 工具包，专为构建、评估和部署复杂 AI 代理而设计，具备灵活性和控制力，适用于 Gemini 模型及其他框架，支持多种部署方式和社区协作，具备丰富的工具生态系统和多代理系统架构。&lt;/p&gt;

&lt;h3&gt;核心要点:&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;ADK 是开源、代码优先的 Python 框架&lt;/strong&gt;，用于构建、评估和部署 AI 代理，提供灵活性和控制力。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;支持多模型与多部署环境&lt;/strong&gt;，不仅优化于 Gemini，而且模型和部署方式均不绑定，兼容其他框架。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;具备丰富的工具生态系统&lt;/strong&gt;，可集成预建工具、自定义函数、OpenAPI 规范及第三方服务，紧密连接 Google 生态。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;支持多代理系统架构&lt;/strong&gt;，通过模块化和灵活的层级设计实现可扩展性与协作能力。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;提供社区支持与贡献渠道&lt;/strong&gt;，包括社区仓库、贡献指南以及定期社区活动，促进生态系统发展。&lt;/li&gt;
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/google/adk-python</guid>
    </item>
    <item>
      <title>lzhoang2801/OpCore-Simplify</title>
      <link>https://github.com/lzhoang2801/OpCore-Simplify</link>
      <description>&lt;p&gt;概要: OpCore Simplify 是一款专为简化 OpenCore EFI 创建而设计的工具，通过自动化关键设置和提供标准配置，显著降低手动操作的复杂度，确保 Hackintosh 安装的准确性与稳定性，同时强调用户需依赖官方资源进行验证和测试。&lt;/p&gt;

&lt;h3&gt;核心要点:&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;唯一基于完整硬件配置生成 OpenCore EFI 的工具&lt;/strong&gt;：不同于其他工具仅提供预设选项，OpCore Simplify 根据用户具体硬件信息自动生成配置，提升兼容性与准确性。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;全面硬件与 macOS 支持&lt;/strong&gt;：支持广泛的 CPU 和 GPU 型号，以及从 macOS High Sierra 到 Tahoe 的多个版本，满足多样化需求。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;自动 ACPI 修补与驱动管理&lt;/strong&gt;：自动检测硬件并添加所需 ACPI 修补和驱动，集成 SSDTTime 工具，优化系统稳定性与性能。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;用户可轻松自定义配置&lt;/strong&gt;：在默认设置基础上，支持手动调整 ACPI 修补、驱动及 SMBIOS 参数，以适应特定需求。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;需依赖社区验证与测试&lt;/strong&gt;：工具虽简化流程，但仍需用户参考 Dortania Guide 和 Hackintosh 社区，自行测试与排查问题。&lt;/li&gt;
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/lzhoang2801/OpCore-Simplify</guid>
    </item>
    <item>
      <title>googlefonts/googlesans-code</title>
      <link>https://github.com/googlefonts/googlesans-code</link>
      <description>&lt;p&gt;概要: Google Sans Code 是一款专为提升代码可读性而设计的固定宽度字体家族，融合了 Google 品牌的视觉风格，适用于如 Gemini 和 Android Studio 等产品，并针对编程语法进行了精细调整，提供从 300 到 800 的宽权重轴支持，便于在不同场景下使用。&lt;/p&gt;  
&lt;h3&gt;核心要点:&lt;/h3&gt;  
&lt;ul&gt;  
  &lt;li&gt;&lt;strong&gt;专为代码优化的固定宽度字体&lt;/strong&gt;，强调清晰度和可读性，兼具 Google 品牌识别度。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;支持多种语言与扩展拉丁字符集&lt;/strong&gt;，增强国际化适用性。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;采用变量字体技术&lt;/strong&gt;，允许通过权重调整适应不同显示需求。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;支持 OpenType 功能&lt;/strong&gt;，如风格集与本地化形式，提升字体灵活性。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;开源授权&lt;/strong&gt;，遵循 SIL Open Font License，鼓励社区贡献与使用。&lt;/li&gt;  
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/googlefonts/googlesans-code</guid>
    </item>
    <item>
      <title>RLinf/RLinf</title>
      <link>https://github.com/RLinf/RLinf</link>
      <description>&lt;p&gt;概要: RLinf 是一个灵活、可扩展的开源基础设施，专为通过强化学习对预训练的基础模型（如大语言模型、视觉语言模型和视觉语言动作模型）进行微调而设计，具备无限学习能力，支持多种仿真环境、模型类型与算法框架，并已在多个任务中取得领先的性能表现。&lt;/p&gt;

&lt;h3&gt;核心要点:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;支持多种模型类型与仿真环境&lt;/strong&gt;: RLinf 支持主流的 VLA（视觉语言动作）模型和 CPU/GPU 并行仿真器，包括 IsaacLab、Behavior 1k、Metaworld、GR00T-N1.5 等，且集成了多种强化学习算法（如 PPO、GRPO、SAC）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;实现高效与灵活的强化学习微调&lt;/strong&gt;: 可直接用于 π₀ 和 π₀.₅ 模型族的强化学习微调，并支持 LoRA 技术与在线强化学习（Online RL），显著提升训练效率和稳定性。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;卓越的数学推理性能&lt;/strong&gt;: 在多个基准（如 AIME 24、AIME 25、GPQA-diamond）中，RLinf 的数学推理模型（如 RLinf-math-1.5B 和 RLinf-math-7B）表现领先，显著优于当前主流模型。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;高度可扩展的系统架构&lt;/strong&gt;: RLinf 通过标准化接口和分布式编程抽象，实现了从单机到大规模 GPU 集群的无缝扩展，同时支持混合执行模式，提升吞吐量至 100%+。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;开发者友好与生态支持&lt;/strong&gt;: 提供 Docker 部署指南、示例库和完整 CI 测试体系，便于快速上手和验证，同时鼓励社区贡献，构建开放协作的 RL 基础设施。&lt;/li&gt;
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/RLinf/RLinf</guid>
    </item>
    <item>
      <title>HKUDS/LightRAG</title>
      <link>https://github.com/HKUDS/LightRAG</link>
      <description>&lt;p&gt;概要: LightRAG是一款简单且快速的检索增强生成（RAG）系统，支持多模态文档处理，并具备多种存储方案和查询模式，显著提升了知识图谱提取、检索性能和系统的可扩展性。该系统集成了Langfuse进行可观测性，并支持灵活的模型配置和数据管理功能，为研究者和企业级应用提供了高效、可定制的RAG解决方案。&lt;/p&gt;

&lt;h3&gt;核心要点:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;高性能、多模态支持&lt;/strong&gt;：LightRAG集成了RAG-Anything，支持处理文本、图像、表格和公式，实现了跨格式的RAG能力。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;灵活的存储系统&lt;/strong&gt;：提供包括JSON、PostgreSQL、MongoDB、Neo4J等在内的多种存储方案，允许根据应用场景选择合适的存储类型。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;智能查询模式&lt;/strong&gt;：支持多模式查询，如Hybrid、Mix、Rerank，并可配置为默认搜索模式，以提升查询结果的相关性。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;扩展性和可维护性&lt;/strong&gt;：引入了RAGAS和Langfuse等评估和追踪工具，增强了系统的可观察性和可扩展性。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;高效部署与优化&lt;/strong&gt;：支持离线部署、容器化运行，并提供对LLM模型参数和上下文长度的优化建议，包括对低RAM环境的适应性。&lt;/li&gt;
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/HKUDS/LightRAG</guid>
    </item>
    <item>
      <title>volcengine/verl</title>
      <link>https://github.com/volcengine/verl</link>
      <description>&lt;p&gt;概要: verl 是由 ByteDance Seed 团队主导并由社区维护的开源强化学习训练库，专为大语言模型（LLMs）设计，具备高度灵活性、高效性和生产就绪性，支持多种 RL 算法和主流 LLM 框架集成，具备多模态、多任务和工具调用能力，并已在多个基准测试中取得领先的强化学习训练效果。&lt;/p&gt;

&lt;h3&gt;核心要点:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;verl 是一个灵活高效的生产级 RL 训练库&lt;/strong&gt;，专为大语言模型优化，支持多种 RL 算法及与主流 LLM 框架（如 FSDP、Megatron-LM、vLLM、SGLang 等）的无缝集成。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;支持多模态和多任务训练&lt;/strong&gt;，包括视觉语言模型（VLMs）和工具调用，已在 math、code、reasoning 等基准测试中取得领先性能。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;具备强大的性能优化能力&lt;/strong&gt;，例如支持 FSDP2、Flash Attention 2、LoRA 等技术，实现高吞吐量与低内存占用，并兼容 AMD ROCm 环境。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;社区活跃且持续发展&lt;/strong&gt;，已集成多种先进 RL 方法（如 PF-PPO、DAPO、VAPO 等），并被多家主流 AI 研究机构与企业采用和贡献。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;支持大规模模型训练&lt;/strong&gt;，可扩展至数百 GPU 和 671B 参数级别，适用于多轮对话与复杂任务训练，如代码生成与数学推理。&lt;/li&gt;
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/volcengine/verl</guid>
    </item>
    <item>
      <title>sansan0/TrendRadar</title>
      <link>https://github.com/sansan0/TrendRadar</link>
      <description>&lt;p&gt;概要：TrendRadar 是一款轻量且易于部署的热点资讯聚合与舆情监控工具，支持35个主流平台的新闻采集，提供智能筛选和实时推送功能，可搭配MCP协议实现AI深度分析，支持微信、飞书、钉钉、Telegram、邮件等多渠道推送，适用于企业及个人用户，提供三种推送模式与精准关键词配置，兼具实时性与灵活性，从多源数据中提取重点，精准推送，帮助用户快捷掌握热点，提升效率，降低信息噪音。&lt;/p&gt;

&lt;h3&gt;核心要点:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;支持35个主流平台的全网热点聚合&lt;/strong&gt;，为用户提供实时、全面的新闻信息。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;AI智能分析&lt;/strong&gt;，基于MCP协议，支持自然语言交互及13种分析工具，提供趋势追踪、情感分析、相似检索等功能。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;灵活的推送模式&lt;/strong&gt;，包括当日汇总、当前榜单及增量监控，满足不同用户对信息更新频率的需求。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;简化部署流程&lt;/strong&gt;，零编程基础即可一键Fork或Docker部署，实现30秒网页部署及快速手机通知，适用于忙碌的高管。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;多渠道推送支持&lt;/strong&gt;，并涵盖企业微信、Telegram、邮件等，提供HTML网页报告与实时数据提醒，且支持推送时间窗口控制。&lt;/li&gt;
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/sansan0/TrendRadar</guid>
    </item>
    <item>
      <title>google-agentic-commerce/AP2</title>
      <link>https://github.com/google-agentic-commerce/AP2</link>
      <description>&lt;p&gt;概要: 本文档介绍了Agent Payments Protocol（AP2）的代码示例与演示，旨在展示其在构建安全且可互操作的AI驱动支付系统中的关键功能，提供多种开发工具和运行方式，支持Python及Android平台，并详细说明了如何快速启动和配置AP2环境以实现支付代理的开发与测试。&lt;/p&gt;

&lt;h3&gt;核心要点:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;AP2是构建安全且可互操作的AI支付协议&lt;/strong&gt;，为开发者提供了一套标准化的框架。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;代码示例与演示包含多个场景&lt;/strong&gt;，覆盖核心组件，便于理解与实现。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;支持多种开发工具&lt;/strong&gt;，如ADK和Gemini 2.5 Flash，但并非强制要求。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;提供灵活的认证方式&lt;/strong&gt;，包括Google API Key和Vertex AI，以适配不同环境需求。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;可通过环境变量或.env文件配置运行参数&lt;/strong&gt;，简化开发流程并提升安全性。&lt;/li&gt;
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/google-agentic-commerce/AP2</guid>
    </item>
    <item>
      <title>MODSetter/SurfSense</title>
      <link>https://github.com/MODSetter/SurfSense</link>
      <description>&lt;p&gt;概要: SurfSense 是一款开源的 AI 研究代理工具，作为 NotebookLM 和 Perplexity 的替代方案，能够连接多种外部源并支持个性化知识库管理，提供强大的搜索、自然语言交互、引用式回答以及高效的语音内容生成功能，同时具备自托管能力、隐私保护与本地 LLM 支持，适合需要高度定制与数据安全的用户。&lt;/p&gt;

&lt;h3&gt;核心要点:&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;高度自定义的 AI 研究代理&lt;/strong&gt;：集成个人知识库，支持外部数据源如搜索引擎、Slack、GitHub、Discord 等，功能可扩展。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;跨格式文件支持&lt;/strong&gt;：兼容 50+ 种文件类型，涵盖文档、幻灯片、表格、图片、音频等，支持本地和云端处理。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;隐私与本地部署能力&lt;/strong&gt;：支持 Ollama 本地 LLM 模型，可选自托管模式，避免数据外泄。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;快速生成播客内容&lt;/strong&gt;：基于聊天记录智能生成音频内容，支持多种 TTS 服务，并具备高性能处理能力。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;全面的技术栈与可扩展性&lt;/strong&gt;：采用 FastAPI、PostgreSQL、Celery 等技术，支持自定义部署和功能扩展，社区贡献导向。&lt;/li&gt;
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/MODSetter/SurfSense</guid>
    </item>
    <item>
      <title>AtsushiSakai/PythonRobotics</title>
      <link>https://github.com/AtsushiSakai/PythonRobotics</link>
      <description>&lt;p&gt;概要: PythonRobotics 是一个集成了机器人算法代码与教材的开源项目，涵盖定位、地图构建、SLAM、路径规划与跟踪、机械臂导航、无人机导航及双足机器人等多个模块，提供直观的动画演示和详细的理论说明，旨在帮助开发者和研究者快速理解和实现机器人算法，同时支持多种编程工具和开发环境。&lt;/p&gt;  
&lt;h3&gt;核心要点:&lt;/h3&gt;  
&lt;ul&gt;  
  &lt;li&gt;&lt;strong&gt;集成代码与教材&lt;/strong&gt;：提供机器人算法的实现代码与理论讲解，便于学习和应用。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;广泛覆盖机器人领域&lt;/strong&gt;：包括定位、SLAM、路径规划、跟踪、机械臂、无人机与双足机器人等关键模块。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;可视化与动画演示&lt;/strong&gt;：通过动画 GIF 展示算法效果，增强理解与调试能力。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;低依赖、易使用&lt;/strong&gt;：支持 Python 3.13.x 和主流科学计算库，便于快速部署和开发。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;开源社区支持&lt;/strong&gt;：提供贡献指南、引用方式、赞助渠道及多种授权方式，鼓励合作与推广。&lt;/li&gt;  
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/AtsushiSakai/PythonRobotics</guid>
    </item>
    <item>
      <title>microsoft/call-center-ai</title>
      <link>https://github.com/microsoft/call-center-ai</link>
      <description>&lt;p&gt;概要: 该文本介绍了基于Azure和OpenAI GPT的AI驱动呼叫中心解决方案，允许通过API调用或预设电话号码发起智能语音通话，具备实时交互、多语言支持、语音与文本转换、数据存储、自动提醒、个性化服务等功能，并支持自定义数据收集结构与语音，同时提供本地和云端部署方式，涵盖训练数据、成本估算与生产就绪优化建议。&lt;/p&gt;  

&lt;h3&gt;核心要点:&lt;/h3&gt;  
&lt;ul&gt;  
  &lt;li&gt;&lt;strong&gt;支持API调用和预设电话号码的AI通话功能&lt;/strong&gt;：可直接通过API或配置号码发起智能语音通话，适用于保险、IT支持等场景，且可快速定制以满足不同需求。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;集成Azure与OpenAI实现高智能化与数据安全&lt;/strong&gt;：使用gpt-4.1和gpt-4.1-nano进行语音处理与数据管理，结合RAG（检索增强生成）技术确保敏感数据合规处理。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;高可扩展和可定制架构&lt;/strong&gt;：采用容器化、无服务器部署，支持实时语音流、多语言和语音风格定制，并且通过Azure AI Search实现训练数据的灵活管理。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;生产级部署和监控&lt;/strong&gt;：提供完整的部署流程与配置选项，支持Azure Application Insights用于应用监控，并可结合Dev Tunnel和本地测试实现快速迭代。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;成本与性能优化建议&lt;/strong&gt;：提供了详细的月度成本估算，包含语音服务、LLM调用、存储等模块，并通过模型调整、缓存和性能测试提升响应延迟和对话质量。&lt;/li&gt;  
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/microsoft/call-center-ai</guid>
    </item>
  </channel>
</rss>