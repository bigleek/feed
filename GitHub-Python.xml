<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>GitHub-Python</title>
    <link>https://mshibanami.github.io/GitHubTrendingRSS/daily/python.xml</link>
    <description>Summarized RSS feed for GitHub-Python</description>
    <atom:link href="https://mshibanami.github.io/GitHubTrendingRSS/daily/python.xml" rel="self" type="application/rss+xml"/>
    <item>
      <title>microsoft/agent-lightning</title>
      <link>https://github.com/microsoft/agent-lightning</link>
      <description>&lt;p&gt;概要: Agent Lightning 是一个创新的AI代理训练平台，支持几乎零代码修改地对多种AI代理框架或独立代理进行优化，涵盖强化学习、自动提示优化等算法，旨在简化代理训练流程并实现持续改进。&lt;/p&gt;

&lt;h3&gt;核心要点:&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;几乎零代码修改实现代理训练与优化&lt;/strong&gt;：Agent Lightning 允许用户在不修改现有代码的情况下，对AI代理进行训练和优化。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;兼容多代理框架与独立开发&lt;/strong&gt;：支持包括LangChain、OpenAI Agent SDK、AutoGen、CrewAI、Microsoft Agent Framework在内的多种主流框架，甚至可适用于无框架的Python OpenAI实现。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;支持多代理系统的差异化优化&lt;/strong&gt;：可选择性地优化一个或多个代理，针对不同任务或角色进行定制化训练。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;提供高效训练架构与中央存储系统&lt;/strong&gt;：通过LightningStore集中管理任务、资源与训练轨迹，并结合算法进行反馈学习和资源更新。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;遵循Microsoft负责任AI标准并采用MIT许可&lt;/strong&gt;：项目已通过微软负责任AI认证，且开源代码遵循MIT许可协议，便于社区参与与合规使用。&lt;/li&gt;
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/microsoft/agent-lightning</guid>
    </item>
    <item>
      <title>Shubhamsaboo/awesome-llm-apps</title>
      <link>https://github.com/Shubhamsaboo/awesome-llm-apps</link>
      <description>&lt;p&gt;概要: 该文本介绍了由多个主流和开源大语言模型（如OpenAI、Anthropic、Gemini、Qwen、Llama等）构建的一系列创新性AI应用，涵盖AI代理、RAG（检索增强生成）、多代理协作、语音助手及多个领域专用工具，旨在展示LLMs在不同场景中的实际应用价值，并鼓励社区参与与贡献，同时提供详细的教程和优化方案以提升效率与降低成本。&lt;/p&gt;

&lt;h3&gt;核心要点:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;丰富的LLM应用场景&lt;/strong&gt;：涵盖代码、研究、医疗、旅行、金融、销售、教学、设计等多个领域，提供多样化的AI Agent解决方案。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;支持多种模型与技术整合&lt;/strong&gt;：结合OpenAI、Anthropic、Gemini及开源模型，支持RAG、MCP、多代理协作和语音交互等技术。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;优化成本与性能的工具&lt;/strong&gt;：提供如TOON格式、Headroom Context Optimization等工具，有效降低LLM API调用成本及提升效率。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;社区驱动与开源生态发展&lt;/strong&gt;：项目强调开源协作，鼓励开发者学习、贡献并推动LLM应用生态的成长。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;操作指南与教程资源丰富&lt;/strong&gt;：包含详细的安装步骤和教程，便于开发者快速上手并扩展应用。&lt;/li&gt;
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/Shubhamsaboo/awesome-llm-apps</guid>
    </item>
    <item>
      <title>open-webui/open-webui</title>
      <link>https://github.com/open-webui/open-webui</link>
      <description>&lt;p&gt;概要: Open WebUI 是一个功能丰富、易于使用的自托管AI平台，支持多种大语言模型（如Ollama和OpenAI API），具备离线运行、RAG推理引擎、多模型交互、企业级安全和可扩展性，适合构建定制化的AI交互体验。&lt;/p&gt;

&lt;h3&gt;核心要点:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;离线运行与RAG整合&lt;/strong&gt;：支持完全离线操作，并内置RAG推理引擎，结合9种向量数据库和多种内容提取工具，提升AI对话的准确性和上下文能力。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;多模型并发支持&lt;/strong&gt;：允许用户同时与多种AI模型进行交互，利用不同模型的专长实现更优化的响应。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;灵活的部署方式&lt;/strong&gt;：提供Docker、Kubernetes、pip等多种安装方式，并支持GPU加速和Ollama集成，适配不同硬件环境。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;企业级安全与权限管理&lt;/strong&gt;：具备基于角色的访问控制（RBAC）、用户组划分、LDAP/AD集成、SCIM 2.0自动用户管理，确保数据和系统安全。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;移动端友好与可定制性&lt;/strong&gt;：支持PWA离线使用，拥有响应式设计和自定义主题/品牌功能，提升用户体验与企业形象。&lt;/li&gt;
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/open-webui/open-webui</guid>
    </item>
    <item>
      <title>cheahjs/free-llm-api-resources</title>
      <link>https://github.com/cheahjs/free-llm-api-resources</link>
      <description>&lt;p&gt;概要: 本文汇总了多个提供免费或试用额度的LLM推理API资源，涵盖不同平台的模型与使用限制，强调了不要滥用以免服务被终止，并明确排除了非合法的服务。用户可根据需求选择具有不同请求频率、令牌限制及模型支持的资源，部分平台还提供免费试用或订阅信用额度。&lt;/p&gt;  
&lt;h3&gt;核心要点:&lt;/h3&gt;  
&lt;ul&gt;  
  &lt;li&gt;&lt;strong&gt;多种免费LLM推理API服务&lt;/strong&gt;：包括OpenRouter、Google AI Studio、NVIDIA NIM、Mistral、HuggingFace、Vercel AI Gateway、Cerebras、Groq、Cohere、GitHub Models、Cloudflare Workers AI和Google Cloud Vertex AI等。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;免费服务存在使用限制&lt;/strong&gt;：如OpenRouter的20请求/分钟、50请求/天，部分模型共享配额，而Cohere仅限1,000请求/月。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;部分平台提供试用信用额度&lt;/strong&gt;：如Fireworks（$1）、Baseten（$30）、Novita（$0.5/年）等，适用于不同模型和使用场景。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;需注意隐私与数据使用&lt;/strong&gt;：如Google AI Studio在非欧盟地区使用模型数据时可能用于训练。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;某些服务要求验证信息&lt;/strong&gt;：如NVIDIA NIM、Cohere、NLP Cloud等需要手机验证以确保合规性。&lt;/li&gt;  
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/cheahjs/free-llm-api-resources</guid>
    </item>
    <item>
      <title>karpathy/nanochat</title>
      <link>https://github.com/karpathy/nanochat</link>
      <description>&lt;p&gt;概要: nanochat 是一个简化且高效的实验平台，专为在单个 GPU 节点上训练大型语言模型（LLM）而设计，通过调整一个参数 --depth 控制模型复杂度，自动优化其他超参数，使得用户可以在远低于 $100 的成本内快速训练出具备 GPT-2 能力的模型，并通过类 ChatGPT 的 Web 界面进行交互。&lt;/p&gt;

&lt;h3&gt;核心要点:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;简化训练流程&lt;/strong&gt;: nanochat 提供了一整套从数据预处理、训练到评估和推理的模块，代码精简且易于修改，适合快速实验。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;单参数控制模型复杂度&lt;/strong&gt;: 通过 --depth 参数定义模型层数，自动计算其余超参数，实现计算资源最优利用。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;低成本高效训练&lt;/strong&gt;: 使用 8XH100 GPU 节点，3 小时即可完成 GPT-2 级别模型的训练，成本仅为 $72，对比 2019 年的 $43,000 有显著下降。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;支持多种运行环境&lt;/strong&gt;: 代码兼容单 GPU、CPU 和 Apple Silicon，但性能会受到一定影响，需调整参数以适应不同硬件条件。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;注重社区协作与开发透明度&lt;/strong&gt;: 通过 leaderboard 激励进展，鼓励开源贡献，并要求提交代码时披露 LLM 相关部分的来源和理解水平。&lt;/li&gt;
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/karpathy/nanochat</guid>
    </item>
    <item>
      <title>Jeffallan/claude-skills</title>
      <link>https://github.com/Jeffallan/claude-skills</link>
      <description>&lt;p&gt;概要: 该文本介绍了“Claude Skills”项目，提供66项针对全栈开发者的专业技能，涵盖12个领域，通过上下文感知激活机制与多技能工作流实现高效协作，并整合Jira和Confluence进行项目管理，旨在将Claude打造成开发者们的专家级配对编程工具。&lt;/p&gt;  
&lt;h3&gt;核心要点:&lt;/h3&gt;  
&lt;ul&gt;  
  &lt;li&gt;&lt;strong&gt;提供66项全栈开发技能，覆盖12大领域&lt;/strong&gt;，包括编程语言、前后端框架、基础设施、API设计、测试、DevOps、安全、数据/机器学习等。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;基于上下文自动激活对应技能&lt;/strong&gt;，如“Implement JWT authentication in my NestJS API”会自动触发NestJS专家模块。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;支持多技能协同工作流&lt;/strong&gt;，适用于复杂任务如功能开发、漏洞排查和安全加固，增强开发效率与质量。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;集成Atlassian MCP服务器实现项目流程管理&lt;/strong&gt;，包括从需求分析到回顾的全流程，与Jira和Confluence深度整合。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;项目提供完整文档与开放贡献机制&lt;/strong&gt;，便于开发者进行技能添加、文档撰写及反馈提交，持续优化工具。&lt;/li&gt;  
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/Jeffallan/claude-skills</guid>
    </item>
    <item>
      <title>HKUDS/RAG-Anything</title>
      <link>https://github.com/HKUDS/RAG-Anything</link>
      <description>&lt;p&gt;概要: RAG-Anything是一个全面的多模态RAG框架，支持文本、图像、表格和公式等多样化内容的无缝处理与查询，通过统一的工具整合提升了学术研究、企业知识管理等场景下的信息检索效率，同时具备灵活的解析模式和自定义扩展能力，结合多模态知识图谱与智能检索机制，实现更精准的语义理解和上下文关联分析。&lt;/p&gt;

&lt;h3&gt;核心要点:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;全面的多模态支持&lt;/strong&gt;：集成处理PDF、Office文档、图像、表格、公式等多种文档格式，并支持自定义内容类型。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;多模态内容理解与分析&lt;/strong&gt;：内置视觉分析、表格解析和公式识别模块，能够对文档中的多元内容进行语义提取和关系推理。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;基于LightRAG的统一框架&lt;/strong&gt;：构建在LightRAG之上，兼容现有工作流，并可扩展支持多种解析方式（如MinerU和Docling）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;智能检索与混合模式查询&lt;/strong&gt;：结合向量相似度搜索和知识图谱遍历算法，支持文本、图像增强、多模态内容增强等多种查询方式。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;灵活的配置与扩展能力&lt;/strong&gt;：提供多种解析参数和自定义模态处理器接口，支持快速部署与特定业务场景的定制化处理。&lt;/li&gt;
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/HKUDS/RAG-Anything</guid>
    </item>
    <item>
      <title>mvt-project/mvt</title>
      <link>https://github.com/mvt-project/mvt</link>
      <description>&lt;p&gt;概要: MVT（Mobile Verification Toolkit）是一款由Amnesty International Security Lab于2021年7月推出的移动设备数字取证工具，旨在通过自动化手段识别Android和iOS设备可能遭受的间谍软件攻击迹象，并结合公开与非公开的情报进行深入分析，特别关注对公民社会和边缘群体的保护。&lt;/p&gt;

&lt;h3&gt;核心要点:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;MVT是专为技术人员和调查人员设计的数字取证工具。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MVT支持使用公开的指示器（IOCs）扫描设备，但无法保证检测全面性。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;可靠的取证分析需要非公开情报和威胁情报支持。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MVT可通过PyPI或源码安装，且需注意依赖项与已知问题。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MVT的目的是确保设备的合法取证，防止隐私侵犯。&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/mvt-project/mvt</guid>
    </item>
    <item>
      <title>anthropics/claude-quickstarts</title>
      <link>https://github.com/anthropics/claude-quickstarts</link>
      <description>&lt;p&gt;概要: Claude Quickstarts 是一系列项目集合，旨在帮助开发者快速构建可部署的应用，利用 Claude API 提供的自然语言处理、数据分析、计算机控制与自动化等功能，为不同应用场景提供可定制的开发基础。&lt;/p&gt;  
&lt;h3&gt;核心要点:&lt;/h3&gt;  
&lt;ul&gt;  
  &lt;li&gt;&lt;strong&gt;提供多个可部署应用示例&lt;/strong&gt;：涵盖客户支持、财务分析、计算机控制、浏览器自动化和自主编程等场景，帮助开发者快速入门。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;支持 Claude API 能力的全面展示&lt;/strong&gt;：包括自然语言理解生成、交互式数据可视化、计算机使用工具以及浏览器自动化接口。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;具备可扩展和可定制性&lt;/strong&gt;：每个项目均提供 README 和设置说明，开发者可按需调整以满足自身业务需求。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;鼓励社区参与与贡献&lt;/strong&gt;：开放源码仓库，支持开发者提交新项目或改进建议，促进生态建设。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;提供丰富的学习资源&lt;/strong&gt;：包括 API 文档、代码示例及基础课程，助力开发者深入了解和掌握 Claude API 的使用。&lt;/li&gt;  
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/anthropics/claude-quickstarts</guid>
    </item>
    <item>
      <title>GetStream/Vision-Agents</title>
      <link>https://github.com/GetStream/Vision-Agents</link>
      <description>&lt;p&gt;概要: Stream 的 Open Vision Agents 提供了一套快速构建多模态视频AI代理的工具，支持与多种模型和视频提供商集成，借助其边缘网络实现超低延迟的实时视频处理与交互，适用于体育教学、安全监控、隐形助手等多种场景。&lt;/p&gt;

&lt;h3&gt;核心要点:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;多模态实时视频AI代理开发工具&lt;/strong&gt;：Open Vision Agents 支持构建可观看、聆听并理解视频的智能代理，结合YOLO、Gemini、OpenAI等模型实现高效视频分析。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;超低延迟与边缘网络支持&lt;/strong&gt;：利用Stream的边缘网络实现音频与视频延迟低于30ms，支持500ms快速连接，保障实时交互体验。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;开放兼容性与灵活扩展&lt;/strong&gt;：虽由Stream开发，但支持连接任何视频边缘网络，并提供丰富的SDK支持React、Android、iOS等平台。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;支持语音与视频双向处理&lt;/strong&gt;：包含语音转文本（STT）、文本转语音（TTS）和语音转语音（Speech↔Text↔Speech）功能，提升语音交互流畅度。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;集成多种第三方AI服务&lt;/strong&gt;：支持AWS Bedrock、Gemini、OpenAI、ElevenLabs等主流平台和模型，提供开箱即用的插件生态。&lt;/li&gt;
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/GetStream/Vision-Agents</guid>
    </item>
    <item>
      <title>docling-project/docling</title>
      <link>https://github.com/docling-project/docling</link>
      <description>&lt;p&gt;概要: Docling 是一款专为通用 AI（gen AI）设计的高效文档处理工具，支持多种格式解析与转换，包括 PDF、图像、音频及 LaTeX 文件，并提供与主流 AI 框架的无缝集成，适用于敏感数据和隔离网络环境，同时具备 CLI 和 MCP 服务器功能，便于快速部署与扩展。&lt;/p&gt;  
&lt;h3&gt;核心要点:&lt;/h3&gt;  
&lt;ul&gt;  
  &lt;li&gt;&lt;strong&gt;支持多种文档格式解析与转换&lt;/strong&gt;，包括 PDF、DOCX、PPTX、图像、音频及 LaTeX。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;提供高级 PDF 理解功能&lt;/strong&gt;，涵盖布局、阅读顺序、表格结构、公式识别及图像分类。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;内置 CLI 工具&lt;/strong&gt;，便于快速运行转换任务，并支持与 Visual Language Models（如 GraniteDocling）集成。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;适用于敏感数据和隔离网络环境&lt;/strong&gt;，具备本地执行能力，保障数据安全性。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;与主流 AI 框架无缝集成&lt;/strong&gt;，如 LangChain、LlamaIndex、Crew AI 和 Haystack，加速 AI 应用开发。&lt;/li&gt;  
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/docling-project/docling</guid>
    </item>
    <item>
      <title>music-assistant/server</title>
      <link>https://github.com/music-assistant/server</link>
      <description>&lt;p&gt;概要: Music Assistant 是一款免费且开源的媒体库管理工具，用于连接流媒体服务和多种智能音箱，其核心服务器需运行在持续在线的设备上，如树莓派、NAS 或 Intel NUC，并推荐与 Home Assistant 配合使用以实现自动化功能，安装需依赖 Docker 容器或 Home Assistant 插件，无法作为独立的 PyPI 包运行。&lt;/p&gt;  
&lt;h3&gt;核心要点:&lt;/h3&gt;  
&lt;ul&gt;  
  &lt;li&gt;&lt;strong&gt;Music Assistant 是免费且开源的媒体库管理工具&lt;/strong&gt;，支持连接流媒体服务与多种智能音箱。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;服务器是其核心组件&lt;/strong&gt;，需部署在始终在线的设备上，如树莓派、NAS 或 Intel NUC。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;推荐与 Home Assistant 配合使用&lt;/strong&gt;，以实现自动化控制与集成。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;安装方式依赖 Docker 容器或 Home Assistant 插件&lt;/strong&gt;，不可作为独立的 PyPI 包运行。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;技术支持与文档信息明确&lt;/strong&gt;，包含官方文档、测试版文档及问题反馈渠道。&lt;/li&gt;  
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/music-assistant/server</guid>
    </item>
    <item>
      <title>Zipstack/unstract</title>
      <link>https://github.com/Zipstack/unstract</link>
      <description>&lt;p&gt;概要: Unstract 是一个无代码的 LLM 平台，提供 API 和 ETL 管道功能，用于将非结构化文档转换为结构化数据，支持高准确率、低成本的自动化流程，并兼容多种 LLM、数据库及云存储系统，适用于企业级和自托管部署。&lt;/p&gt;

&lt;h3&gt;核心要点:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;无代码 LLM 平台&lt;/strong&gt;：提供 Prompt Studio 工具，帮助用户定义结构化数据模式，实现高精度文档提取，一键发布 API。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;多集成类型支持&lt;/strong&gt;：包括 MCP 服务器、API 部署、ETL 管道和 n8n 节点，适应不同团队和技术环境的需求。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;广泛的文件类型支持&lt;/strong&gt;：覆盖 Word、Excel、PDF、图像等多种格式，确保全面的文档处理能力。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;企业级功能增强&lt;/strong&gt;：提供 LLMChallenge、单次提取、摘要提取、人工校验及 SSO 认证，确保高可靠性与安全性。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;灵活部署选项&lt;/strong&gt;：支持云托管和自托管，包含 14 天免费试用，并提供详细的快速入门指南。&lt;/li&gt;
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/Zipstack/unstract</guid>
    </item>
    <item>
      <title>ruvnet/wifi-densepose</title>
      <link>https://github.com/ruvnet/wifi-densepose</link>
      <description>&lt;p&gt;概要: WiFi DensePose 是一种革命性的基于WiFi的高精度人体姿态估算系统，无需摄像头即可实现穿透墙壁的实时全身体态追踪，具备隐私保护、多目标跟踪、综合分析功能及企业级API，通过Rust实现高性能优化，并支持灾难响应等定制化应用场景。&lt;/p&gt;  
&lt;h3&gt;核心要点:&lt;/h3&gt;  
&lt;ul&gt;  
  &lt;li&gt;&lt;strong&gt;隐私优先、无摄像头的人体姿态检测&lt;/strong&gt;：利用WiFi信号进行实时、隐私保护性强的全身体态追踪，适用于多场景。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;Rust高性能实现&lt;/strong&gt;：相比Python实现有数百倍性能提升，支持WASM与小型化部署，资源占用显著降低。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;灾难响应模块WiFi-Mat&lt;/strong&gt;：支持地震、山体滑坡等场景下的生存者定位与自动分类，具备实时预警系统。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;全面测试与部署支持&lt;/strong&gt;：100%测试覆盖率，支持Docker、Kubernetes、Terraform和Ansible等多种部署方式。&lt;/li&gt;  
  &lt;li&gt;&lt;strong&gt;系统架构模块化&lt;/strong&gt;：包含CSI处理器、信号处理器、神经网络模型、多目标追踪器等核心组件，实现数据采集、处理、分析与传输全流程。&lt;/li&gt;  
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/ruvnet/wifi-densepose</guid>
    </item>
    <item>
      <title>awslabs/agent-squad</title>
      <link>https://github.com/awslabs/agent-squad</link>
      <description>&lt;p&gt;概要: Agent Squad 是一个灵活高效的开源框架，用于协调多个 AI 代理处理复杂对话，支持智能意图分类、多语言实现和跨平台部署，并提供了 SupervisorAgent 实现多代理团队协作和上下文管理，适用于从简单聊天机器人到企业级 AI 系统的广泛场景。&lt;/p&gt;  
&lt;h3&gt;核心要点:&lt;/h3&gt;  
&lt;ul&gt;  
&lt;li&gt;&lt;strong&gt;重新命名并统一名称&lt;/strong&gt;: 项目从“Multi-Agent Orchestrator”更名为“Agent Squad”，统一使用新名称进行开发和讨论。&lt;/li&gt;  
&lt;li&gt;&lt;strong&gt;智能意图分类与路由&lt;/strong&gt;: 根据上下文和内容动态分配用户请求到最合适的 AI 代理，提升对话处理的准确性与效率。&lt;/li&gt;  
&lt;li&gt;&lt;strong&gt;支持多语言与跨平台部署&lt;/strong&gt;: 以 Python 和 TypeScript 实现，适用于 AWS Lambda、本地环境及任意云平台。&lt;/li&gt;  
&lt;li&gt;&lt;strong&gt;SupervisorAgent 支持团队协作&lt;/strong&gt;: 引入“agent-as-tools”架构，实现多个专用 AI 代理的并行处理与动态任务分配，提升复杂任务处理能力。&lt;/li&gt;  
&lt;li&gt;&lt;strong&gt;模块化安装与扩展性强&lt;/strong&gt;: 提供多种安装选项，支持按需安装不同 AI 服务的集成模块，如 AWS、Anthropic、OpenAI，增强灵活性和可定制性。&lt;/li&gt;  
&lt;/ul&gt;</description>
      <pubDate/>
      <guid>https://github.com/awslabs/agent-squad</guid>
    </item>
  </channel>
</rss>